{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 学習中に正則化を強める\n",
    "\n",
    "物性値は\n",
    "$\\theta_F = \\pi/100$,$\\eta_F=1\\degree$とする。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#------------------------\n",
    "# Google Colab上でのみ実行\n",
    "#------------------------\n",
    "import time\n",
    "%env TOKEN=*************************************\n",
    "! git clone https://$$TOKEN@github.com/konnitiha3/MOD2NN.git\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/MOD2NN')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.8.0\n",
      "Python: 3.8.11 (default, Aug 16 2021, 12:04:33) \n",
      "[Clang 12.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from Faraday.two_dim.module.lib.layers import *\n",
    "from Faraday.two_dim.module.lib import regularizer\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-5000:]\n",
    "y_val = y_train[-5000:]\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "ds_train_batch = ds_train.batch(64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#@title デフォルトのタイトル テキスト\n",
    "wavelength = 633.0e-9 #@param {type:\"number\"}\n",
    "d = 1.0e-6 #@param {type:\"number\"}\n",
    "n = 1.5 #@param {type:\"number\"}\n",
    "z = 0.7e-3 #@param {type:\"number\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def create_model(**kwargs):\n",
    "    shape = (100, 100)\n",
    "    inputs = tf.keras.Input((28, 28))\n",
    "    theta = np.pi / 100\n",
    "    eta = np.tan(1.0*np.pi/100)\n",
    "    l1 = kwargs[\"l1\"]\n",
    "    tf.random.set_seed(kwargs[\"seed\"])\n",
    "    x = ImageResizing(shape)(inputs)\n",
    "    x = IntensityToElectricField(shape)(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=n, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.SymmetricShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=n, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.SymmetricShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=n, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.SymmetricShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=n, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.SymmetricShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=n, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.SymmetricShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=n, method='expand')(x)\n",
    "    x = FaradayRotationByStokes(shape)(x)\n",
    "    x = MNISTDetector(10)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    inputs = tf.keras.Input((28, 28))\n",
    "    x = tf.keras.layers.Flatten(input_shape=(28,28))(inputs)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.Dense(10)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def loss(model, x, y, training):\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets, training=True)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 0.277, Accuracy: 93.180%, Val Loss: 0.247, Val Accuracy: 0.937\n",
      "[[0, 0.2766259, 0.93179995, 0.24696364, 0.9366]]\n",
      "Epoch 001: Loss: 0.255, Accuracy: 93.278%, Val Loss: 0.242, Val Accuracy: 0.938\n",
      "[[0, 0.2766259, 0.93179995, 0.24696364, 0.9366], [1, 0.2552488, 0.9327818, 0.24217199, 0.9376]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [51]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     32\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mapply_gradients(\u001B[38;5;28mzip\u001B[39m(grads, model\u001B[38;5;241m.\u001B[39mtrainable_variables))\n\u001B[1;32m     34\u001B[0m     epoch_loss_avg\u001B[38;5;241m.\u001B[39mupdate_state(loss_value)\n\u001B[0;32m---> 35\u001B[0m     \u001B[43mepoch_accuracy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# End Epoch\u001B[39;00m\n\u001B[1;32m     38\u001B[0m train_loss_result\u001B[38;5;241m.\u001B[39mappend(epoch_loss_avg\u001B[38;5;241m.\u001B[39mresult())\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/keras/utils/metrics_utils.py:70\u001B[0m, in \u001B[0;36mupdate_state_wrapper.<locals>.decorated\u001B[0;34m(metric_obj, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     65\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrying to run metric.update_state in replica context when \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     66\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe metric was not created in TPUStrategy scope. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMake sure the keras Metric is created in TPUstrategy scope. \u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf_utils\u001B[38;5;241m.\u001B[39mgraph_context_for_symbolic_tensors(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 70\u001B[0m   update_op \u001B[38;5;241m=\u001B[39m \u001B[43mupdate_state_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m update_op \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# update_op will be None in eager execution.\u001B[39;00m\n\u001B[1;32m     72\u001B[0m   metric_obj\u001B[38;5;241m.\u001B[39madd_update(update_op)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/keras/metrics.py:178\u001B[0m, in \u001B[0;36mMetric.__new__.<locals>.update_state_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    176\u001B[0m control_status \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\n\u001B[1;32m    177\u001B[0m ag_update_state \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mtf_convert(obj_update_state, control_status)\n\u001B[0;32m--> 178\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mag_update_state\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    687\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    688\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 689\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    691\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_in_allowlist_cache(f, options):\n\u001B[1;32m    330\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: from cache\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n\u001B[0;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mDISABLED:\n\u001B[1;32m    334\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: AutoGraph is disabled in context\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    455\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 458\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/keras/metrics.py:730\u001B[0m, in \u001B[0;36mMeanMetricWrapper.update_state\u001B[0;34m(self, y_true, y_pred, sample_weight)\u001B[0m\n\u001B[1;32m    728\u001B[0m ag_fn \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mtf_convert(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fn, tf\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mautograph\u001B[38;5;241m.\u001B[39mcontrol_status_ctx())\n\u001B[1;32m    729\u001B[0m matches \u001B[38;5;241m=\u001B[39m ag_fn(y_true, y_pred, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fn_kwargs)\n\u001B[0;32m--> 730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mMeanMetricWrapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_state\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    731\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmatches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/keras/metrics.py:469\u001B[0m, in \u001B[0;36mReduce.update_state\u001B[0;34m(self, values, sample_weight)\u001B[0m\n\u001B[1;32m    465\u001B[0m       values \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_mean(\n\u001B[1;32m    466\u001B[0m           values, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(weight_ndim, ndim)))\n\u001B[1;32m    467\u001B[0m   values \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmultiply(values, sample_weight)\n\u001B[0;32m--> 469\u001B[0m value_sum \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcontrol_dependencies([value_sum]):\n\u001B[1;32m    471\u001B[0m   update_total_op \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtotal\u001B[38;5;241m.\u001B[39massign_add(value_sum)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:2311\u001B[0m, in \u001B[0;36mreduce_sum\u001B[0;34m(input_tensor, axis, keepdims, name)\u001B[0m\n\u001B[1;32m   2248\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmath.reduce_sum\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreduce_sum\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m   2249\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[1;32m   2250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreduce_sum\u001B[39m(input_tensor, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   2251\u001B[0m   \u001B[38;5;124;03m\"\"\"Computes the sum of elements across dimensions of a tensor.\u001B[39;00m\n\u001B[1;32m   2252\u001B[0m \n\u001B[1;32m   2253\u001B[0m \u001B[38;5;124;03m  This is the reduction operation for the elementwise `tf.math.add` op.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2308\u001B[0m \u001B[38;5;124;03m  @end_compatibility\u001B[39;00m\n\u001B[1;32m   2309\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2311\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreduce_sum_with_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2312\u001B[0m \u001B[43m                              \u001B[49m\u001B[43m_ReductionDims\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:2323\u001B[0m, in \u001B[0;36mreduce_sum_with_dims\u001B[0;34m(input_tensor, axis, keepdims, name, dims)\u001B[0m\n\u001B[1;32m   2315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreduce_sum_with_dims\u001B[39m(input_tensor,\n\u001B[1;32m   2316\u001B[0m                          axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   2317\u001B[0m                          keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   2318\u001B[0m                          name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   2319\u001B[0m                          dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   2320\u001B[0m   keepdims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m keepdims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(keepdims)\n\u001B[1;32m   2321\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _may_reduce_to_scalar(\n\u001B[1;32m   2322\u001B[0m       keepdims, axis,\n\u001B[0;32m-> 2323\u001B[0m       \u001B[43mgen_math_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/miniforge3/envs/tensorflow25/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:11192\u001B[0m, in \u001B[0;36m_sum\u001B[0;34m(input, axis, keep_dims, name)\u001B[0m\n\u001B[1;32m  11190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m  11191\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m> 11192\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m  11193\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSum\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkeep_dims\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_dims\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m  11194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m  11195\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def train(name, seed):\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    num_epochs = 50\n",
    "    l1_rate = 5\n",
    "\n",
    "    a1 = 0.0\n",
    "    a2 = 1.0e-9\n",
    "    r = 10.0 # 等比級数\n",
    "\n",
    "    model = create_model(l1=a1) #　最初は0\n",
    "    history = []\n",
    "\n",
    "\n",
    "    model_name = name\n",
    "    cholab_path = \"/content/drive/MyDrive/D2NN/\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "        # l1_rateごとにl1を変える\n",
    "        if epoch % l1_rate == 0:\n",
    "            weights = model.get_weights()\n",
    "            l1 = a2*r**(epoch/5) #等比数列\n",
    "            model = create_model(l1=l1)\n",
    "            model.set_weights(weights)\n",
    "\n",
    "        # batch train\n",
    "\n",
    "        for x, y, in ds_train_batch:\n",
    "            loss_value, grads = grad(model, x, y)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            epoch_loss_avg.update_state(loss_value)\n",
    "            epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "        # End Epoch\n",
    "\n",
    "        val_loss = loss(model, x_val, y_val, training=False)\n",
    "\n",
    "        val_accuracy.update_state(y_val, model(x_val, training=False))\n",
    "\n",
    "        history.append([epoch,\n",
    "            epoch_loss_avg.result().numpy(),\n",
    "            epoch_accuracy.result().numpy(),\n",
    "            val_loss.numpy(),\n",
    "            val_accuracy.result().numpy()])\n",
    "\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}, Val Loss: {:.3f}, Val Accuracy: {:.3f}\".format(\n",
    "            epoch,\n",
    "            epoch_loss_avg.result(),\n",
    "            epoch_accuracy.result(),\n",
    "            val_loss.numpy(),\n",
    "            val_accuracy.result()\n",
    "        ))\n",
    "        checkpoint_path = cholab_path + \"checkpoint/\" + model_name + \"/cp-epoch:{:04d}.ckpt\".format(epoch)\n",
    "        model.save_weights(checkpoint_path, save_format=\"tf\")\n",
    "\n",
    "        print(history)\n",
    "\n",
    "    path = cholab_path + \"trained_model/\"+ model_name\n",
    "    model.save(path)\n",
    "\n",
    "    df = pd.DataFrame(history, columns=[\"epoch\", \"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"])\n",
    "    df.to_csv(path + \"/history.csv\")\n",
    "\n",
    "    with open(path + \"/config.json\", 'w') as f:\n",
    "        json.dump(model.get_config(), f, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seeds = np.arang(1,11)\n",
    "for i, seed in enumerate(seeds):\n",
    "    train(\"20220825_\" + str(i+1), seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

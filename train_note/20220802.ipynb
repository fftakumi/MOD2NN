{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "ガラス基盤上に成膜したもの物性を使った学習"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "h-6RT97yNzSP",
    "outputId": "a95bb9c2-2b33-4420-cc46-b15e8b1bb5c5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: TOKEN=*************************************\n",
      "Cloning into 'MOD2NN'...\n",
      "remote: Enumerating objects: 980, done.\u001B[K\n",
      "remote: Counting objects: 100% (151/151), done.\u001B[K\n",
      "remote: Compressing objects: 100% (86/86), done.\u001B[K\n",
      "remote: Total 980 (delta 60), reused 118 (delta 45), pack-reused 829\u001B[K\n",
      "Receiving objects: 100% (980/980), 35.91 MiB | 7.30 MiB/s, done.\n",
      "Resolving deltas: 100% (539/539), done.\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#------------------------\n",
    "# Google Colab上でのみ実行\n",
    "#------------------------\n",
    "import time\n",
    "%env TOKEN=*************************************\n",
    "! git clone https://$$TOKEN@github.com/konnitiha3/MOD2NN.git\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/MOD2NN')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Faraday.two_dim.module.lib.layers import *\n",
    "from Faraday.two_dim.module.lib import regularizer\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-5000:]\n",
    "y_val = y_train[-5000:]\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title デフォルトのタイトル テキスト\n",
    "wavelength = 532.0e-9 #@param {type:\"number\"}\n",
    "d = 1.0e-6 #@param {type:\"number\"}\n",
    "n = 1.5 #@param {type:\"number\"}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(**kwargs):\n",
    "    tf.random.set_seed(1)\n",
    "    shape = (100, 100)\n",
    "    inputs = tf.keras.Input((28, 28))\n",
    "    theta = -2.79 * np.pi / 180\n",
    "    eta = np.arctan(1.24 * np.pi/180)/2\n",
    "    l1=1.0e-5\n",
    "    z = kwargs[\"z\"]\n",
    "    print(kwargs)\n",
    "    x = ImageResizing(shape)(inputs)\n",
    "    x = ImageBinarization(0.5, 0.0, 1.0)(x)\n",
    "    x = IntensityToElectricField(shape)(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.ShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=0.7e-3, d=d, n=1.51, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.ShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=1.00, method='expand')(x)\n",
    "    # x = Polarizer(shape)(x)\n",
    "    #x =ElectricFieldToIntensity(shape)(x)\n",
    "    #x = MNISTFilter(shape)(x)\n",
    "    x = FaradayRotationByStokes(shape)(x)\n",
    "    # x = Argument(shape)(x)\n",
    "    #x = MNISTDetector(10)(x)\n",
    "    x = CircleOnCircumferenceDetector(10, 30, 5)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_list = np.array([0.5e-3, 0.6e-3, 0.7e-3, 0.8e-3, 0.9e-3, 1.0e-3])\n",
    "\n",
    "for i, z in enumerate(z_list):\n",
    "    model = create_model(z=z)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,  # category: sparse_categorical_crossentropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs = 50\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy',\n",
    "        min_delta=0.05,\n",
    "        patience=2,\n",
    "    )\n",
    "\n",
    "    model_name = \"20220802_\" + str(i + 3)\n",
    "    cholab_path = \"/content/drive/MyDrive/D2NN/\"\n",
    "    checkpoint_path = cholab_path + \"checkpoint/\" + model_name + \"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # チェックポイントコールバックを作る\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "\n",
    "    logdir = os.path.join(cholab_path +\"logs\", model_name)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    result = model.fit(x_train,\n",
    "                       y_train,\n",
    "                       batch_size=64,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=(x_val, y_val),\n",
    "                       callbacks=[cp_callback]\n",
    "                       )\n",
    "\n",
    "    path = cholab_path + \"trained_model/\"+ model_name\n",
    "    model.save(path)\n",
    "\n",
    "    df = pd.DataFrame(result.history)\n",
    "    df.to_csv(path + \"/history.csv\")\n",
    "\n",
    "    with open(path + \"/config.json\", 'w') as f:\n",
    "        json.dump(model.get_config(), f, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/D2NN/trained_model/20220802_*'\n",
    "files = glob.glob(path)\n",
    "p = re.compile(r'\\d+_\\d+')\n",
    "files.sort(reverse=False, key=lambda s: int(p.search(s).group()))\n",
    "acc_list = []\n",
    "for path in files:\n",
    "  model = tf.keras.models.load_model(path)\n",
    "  acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "  bi_model = tf.keras.models.load_model(path)\n",
    "  pattern = r'mo'\n",
    "  mo_layers = []\n",
    "  save = False\n",
    "  each_save = False\n",
    "  for layer in bi_model.layers:\n",
    "      result = re.match(pattern, layer.name)\n",
    "      if result:\n",
    "          mo_layers.append(layer)\n",
    "\n",
    "  for layer in mo_layers:\n",
    "      w = layer.get_weights()\n",
    "      bi_w = np.where(w[0]>0, np.pi/2, -np.pi/2)\n",
    "      w[0] = bi_w\n",
    "      layer.set_weights(w)\n",
    "\n",
    "  bi_acc = bi_model.evaluate(x_test, y_test)\n",
    "  acc_list.append([acc[1], bi_acc[1]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(acc_list)\n",
    "df.to_csv(\"acc.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 最適化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install GPyOpt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import GPy\n",
    "import GPyOpt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model(**kwargs):\n",
    "    z = kwargs[\"z\"]\n",
    "    r1 = kwargs[\"r1\"]\n",
    "    r2 = kwargs[\"r2\"]\n",
    "    wavelength = 532.0e-9\n",
    "    d = 1.0e-6\n",
    "    n = 1.5\n",
    "    #tf.random.set_seed(kwargs[\"seed\"])\n",
    "    shape = (100, 100)\n",
    "    inputs = tf.keras.Input((28, 28))\n",
    "    theta = -2.79 * np.pi / 180\n",
    "    eta = np.arctan(1.24 * np.pi/180)/2\n",
    "    l1=1.0e-5\n",
    "    print(kwargs)\n",
    "    x = ImageResizing(shape)(inputs)\n",
    "    x = ImageBinarization(0.5, 0.0, 1.0)(x)\n",
    "    x = IntensityToElectricField(shape)(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.ShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=0.7e-3, d=d, n=1.51, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.ShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=1.00, method='expand')(x)\n",
    "    # x = Polarizer(shape)(x)\n",
    "    #x =ElectricFieldToIntensity(shape)(x)\n",
    "    #x = MNISTFilter(shape)(x)\n",
    "    x = FaradayRotationByStokes(shape)(x)\n",
    "    # x = Argument(shape)(x)\n",
    "    #x = MNISTDetector(10)(x)\n",
    "    x = CircleOnCircumferenceDetector(10, r1, r2)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 0\n",
    "def train(**kwargs):\n",
    "    global count\n",
    "    count += 1\n",
    "    model = create_model(**kwargs)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,  # category: sparse_categorical_crossentropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs = 50\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy',\n",
    "        min_delta=0.05,\n",
    "        patience=2,\n",
    "    )\n",
    "\n",
    "    model_name = \"20220802_BO/\" + str(count)\n",
    "    cholab_path = \"/content/drive/MyDrive/D2NN/\"\n",
    "    checkpoint_path = cholab_path + \"checkpoint/\" + model_name + \"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # チェックポイントコールバックを作る\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "\n",
    "    logdir = os.path.join(cholab_path +\"logs\", model_name)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    result = model.fit(x_train,\n",
    "                       y_train,\n",
    "                       batch_size=64,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=(x_val, y_val),\n",
    "                       callbacks=[cp_callback, tensorboard_callback]\n",
    "                       )\n",
    "\n",
    "    path = cholab_path + \"trained_model/\"+ model_name\n",
    "    model.save(path)\n",
    "\n",
    "    df = pd.DataFrame(result.history)\n",
    "    df.to_csv(path + \"/history.csv\")\n",
    "\n",
    "    with open(path + \"/config.json\", 'w') as f:\n",
    "        json.dump(model.get_config(), f, indent=4)\n",
    "\n",
    "    bi_model = tf.keras.models.load_model(path)\n",
    "    pattern = r'mo'\n",
    "    mo_layers = []\n",
    "    for layer in bi_model.layers:\n",
    "        result = re.match(pattern, layer.name)\n",
    "        if result:\n",
    "            mo_layers.append(layer)\n",
    "\n",
    "    for layer in mo_layers:\n",
    "        w = layer.get_weights()\n",
    "        bi_w = np.where(w[0]>0, np.pi/2, -np.pi/2)\n",
    "        w[0] = bi_w\n",
    "        layer.set_weights(w)\n",
    "    evaluate = bi_model.evaluate(x_test, y_test)\n",
    "    history.append([count, *kwargs, evaluate[0], evaluate[1]])\n",
    "    df = pd.DataFrame(history)\n",
    "    df.to_csv(\"/content/drive/MyDrive/D2NN/trained_model/20220802_BO/bo_history.csv\")\n",
    "\n",
    "    return evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bounds = [{'name': 'z',  'type': 'continuous',  'domain': (0.1e-3, 5.0e-3)},\n",
    "          {'name': 'r1', 'type': 'discrete',  'domain': range(1,50)},\n",
    "          {'name': 'r2', 'type': 'discrete',  'domain': range(1,50)}]\n",
    "\n",
    "constraints = [\n",
    "    {\n",
    "        \"name\": \"constr_1\",\n",
    "        \"constraint\": \"(x[:,1] + x[:,2]) - 50\" # r1 + r2 <= 50\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"constr_2\",\n",
    "        \"constraint\": \"x[:,2] - x[:,1]*0.325\" # r2 <= r1*tan(2pi/10)\n",
    "    }\n",
    "]\n",
    "\n",
    "# ベイズ最適化する関数（上記で書いたブラックボックス）を定義します。\n",
    "# xが入力で、出力はreturnされます。\n",
    "def f(x):\n",
    "    print(x)\n",
    "    evaluation = train(\n",
    "        z = float(x[:,0]),\n",
    "        r1 = float(x[:,1]),\n",
    "        r2 = int(x[:,2]))\n",
    "    print(\"loss:{0} \\t\\t accuracy:{1}\".format(evaluation[0], evaluation[1]))\n",
    "    print(evaluation)\n",
    "    return evaluation[0]\n",
    "\n",
    "# 事前探索を行います。\n",
    "opt_mnist = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds, constraints=constraints)\n",
    "\n",
    "# 最適なパラメータを探索します。\n",
    "opt_mnist.run_optimization(max_iter=20)\n",
    "print(\"optimized parameters: {0}\".format(opt_mnist.x_opt))\n",
    "print(\"optimized loss: {0}\".format(opt_mnist.fx_opt))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0   0  1   2   3         4       5\n0            0   1  z  r1  r2  2.302650  0.1201\n1            1   2  z  r1  r2  1.565276  0.5395\n2            2   3  z  r1  r2  1.995627  0.4887\n3            3   4  z  r1  r2  2.725760  0.4438\n4            4   5  z  r1  r2  2.072187  0.4226\n5            5   6  z  r1  r2  1.829431  0.5087\n6            6   7  z  r1  r2  1.526752  0.5439\n7            7   8  z  r1  r2  1.343696  0.5931\n8            8   9  z  r1  r2  1.644130  0.5841\n9            9  10  z  r1  r2  1.749159  0.3965\n10          10  11  z  r1  r2  1.719966  0.5101\n11          11  12  z  r1  r2  1.671921  0.4565\n12          12  13  z  r1  r2  8.003469  0.2013\n13          13  14  z  r1  r2  1.309466  0.6554\n14          14  15  z  r1  r2  2.166275  0.2931\n15          15  16  z  r1  r2  1.228763  0.6469\n16          16  17  z  r1  r2  2.214418  0.5556\n17          17  18  z  r1  r2  5.278155  0.2268\n18          18  19  z  r1  r2  1.905527  0.3547\n19          19  20  z  r1  r2  1.132703  0.6904\n20          20  21  z  r1  r2  1.155738  0.6623\n21          21  22  z  r1  r2  1.401206  0.6319\n22          22  23  z  r1  r2  1.188589  0.6718",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>2.302650</td>\n      <td>0.1201</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.565276</td>\n      <td>0.5395</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.995627</td>\n      <td>0.4887</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>2.725760</td>\n      <td>0.4438</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>2.072187</td>\n      <td>0.4226</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>6</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.829431</td>\n      <td>0.5087</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>7</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.526752</td>\n      <td>0.5439</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>8</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.343696</td>\n      <td>0.5931</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>9</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.644130</td>\n      <td>0.5841</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>10</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.749159</td>\n      <td>0.3965</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>11</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.719966</td>\n      <td>0.5101</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>12</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.671921</td>\n      <td>0.4565</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>13</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>8.003469</td>\n      <td>0.2013</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>14</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.309466</td>\n      <td>0.6554</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>15</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>2.166275</td>\n      <td>0.2931</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>16</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.228763</td>\n      <td>0.6469</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>17</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>2.214418</td>\n      <td>0.5556</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>18</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>5.278155</td>\n      <td>0.2268</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>19</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.905527</td>\n      <td>0.3547</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>20</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.132703</td>\n      <td>0.6904</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>21</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.155738</td>\n      <td>0.6623</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>22</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.401206</td>\n      <td>0.6319</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>23</td>\n      <td>z</td>\n      <td>r1</td>\n      <td>r2</td>\n      <td>1.188589</td>\n      <td>0.6718</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "df = pd.read_csv(\"../Faraday/two_dim/trained_model/20220802_BO/bo_history.csv\")\n",
    "files = glob.glob(\"../Faraday/two_dim/trained_model/20220802_BO/*/config.json\")\n",
    "p = re.compile(r'\\d+(?=/config.json)')\n",
    "files.sort(reverse=False, key=lambda s: int(p.search(s).group()))\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0   0         1     2   3         4       5\n0            0   1   0.00494   3.0   1  2.302650  0.1201\n1            1   2   0.00487  16.0   8  1.565276  0.5395\n2            2   3  0.001788  13.0  16  1.995627  0.4887\n3            3   4  0.001455  20.0  23  2.725760  0.4438\n4            4   5  0.004056   9.0   4  2.072187  0.4226\n5            5   6  0.001693  13.0  15  1.829431  0.5087\n6            6   7    0.0001  14.0  10  1.526752  0.5439\n7            7   8  0.002715  24.0   8  1.343696  0.5931\n8            8   9  0.001056  30.0  10  1.644130  0.5841\n9            9  10  0.004773   1.0  49  1.749159  0.3965\n10          10  11    0.0001  22.0  10  1.719966  0.5101\n11          11  12  0.001091   1.0  37  1.671921  0.4565\n12          12  13  0.004181   9.0  41  8.003469  0.2013\n13          13  14    0.0001   1.0  21  1.309466  0.6554\n14          14  15     0.005   1.0  12  2.166275  0.2931\n15          15  16    0.0001   1.0  28  1.228763  0.6469\n16          16  17  0.002099  37.0  13  2.214418  0.5556\n17          17  18  0.004865  29.0  21  5.278155  0.2268\n18          18  19     0.005   1.0  25  1.905527  0.3547\n19          19  20    0.0001   1.0  32  1.132703  0.6904\n20          20  21    0.0001   4.0  18  1.155738  0.6623\n21          21  22    0.0001   1.0  18  1.401206  0.6319\n22          22  23    0.0001   8.0  22  1.188589  0.6718",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0.00494</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>2.302650</td>\n      <td>0.1201</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.00487</td>\n      <td>16.0</td>\n      <td>8</td>\n      <td>1.565276</td>\n      <td>0.5395</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0.001788</td>\n      <td>13.0</td>\n      <td>16</td>\n      <td>1.995627</td>\n      <td>0.4887</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4</td>\n      <td>0.001455</td>\n      <td>20.0</td>\n      <td>23</td>\n      <td>2.725760</td>\n      <td>0.4438</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>0.004056</td>\n      <td>9.0</td>\n      <td>4</td>\n      <td>2.072187</td>\n      <td>0.4226</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>6</td>\n      <td>0.001693</td>\n      <td>13.0</td>\n      <td>15</td>\n      <td>1.829431</td>\n      <td>0.5087</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>7</td>\n      <td>0.0001</td>\n      <td>14.0</td>\n      <td>10</td>\n      <td>1.526752</td>\n      <td>0.5439</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>8</td>\n      <td>0.002715</td>\n      <td>24.0</td>\n      <td>8</td>\n      <td>1.343696</td>\n      <td>0.5931</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>9</td>\n      <td>0.001056</td>\n      <td>30.0</td>\n      <td>10</td>\n      <td>1.644130</td>\n      <td>0.5841</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>10</td>\n      <td>0.004773</td>\n      <td>1.0</td>\n      <td>49</td>\n      <td>1.749159</td>\n      <td>0.3965</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>11</td>\n      <td>0.0001</td>\n      <td>22.0</td>\n      <td>10</td>\n      <td>1.719966</td>\n      <td>0.5101</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>12</td>\n      <td>0.001091</td>\n      <td>1.0</td>\n      <td>37</td>\n      <td>1.671921</td>\n      <td>0.4565</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>13</td>\n      <td>0.004181</td>\n      <td>9.0</td>\n      <td>41</td>\n      <td>8.003469</td>\n      <td>0.2013</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>14</td>\n      <td>0.0001</td>\n      <td>1.0</td>\n      <td>21</td>\n      <td>1.309466</td>\n      <td>0.6554</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>15</td>\n      <td>0.005</td>\n      <td>1.0</td>\n      <td>12</td>\n      <td>2.166275</td>\n      <td>0.2931</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>16</td>\n      <td>0.0001</td>\n      <td>1.0</td>\n      <td>28</td>\n      <td>1.228763</td>\n      <td>0.6469</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>17</td>\n      <td>0.002099</td>\n      <td>37.0</td>\n      <td>13</td>\n      <td>2.214418</td>\n      <td>0.5556</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>18</td>\n      <td>0.004865</td>\n      <td>29.0</td>\n      <td>21</td>\n      <td>5.278155</td>\n      <td>0.2268</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>19</td>\n      <td>0.005</td>\n      <td>1.0</td>\n      <td>25</td>\n      <td>1.905527</td>\n      <td>0.3547</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>20</td>\n      <td>0.0001</td>\n      <td>1.0</td>\n      <td>32</td>\n      <td>1.132703</td>\n      <td>0.6904</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>21</td>\n      <td>0.0001</td>\n      <td>4.0</td>\n      <td>18</td>\n      <td>1.155738</td>\n      <td>0.6623</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>22</td>\n      <td>0.0001</td>\n      <td>1.0</td>\n      <td>18</td>\n      <td>1.401206</td>\n      <td>0.6319</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>23</td>\n      <td>0.0001</td>\n      <td>8.0</td>\n      <td>22</td>\n      <td>1.188589</td>\n      <td>0.6718</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, path in enumerate(files):\n",
    "    with open(path, mode=\"r\") as f:\n",
    "        text = json.load(f)\n",
    "        r1 = text['layers'][-2]['config']['r1']\n",
    "        r2 = text['layers'][-2]['config']['r2']\n",
    "        z = text['layers'][-4]['config']['z']\n",
    "        df.iat[i,2] = z\n",
    "        df.iat[i,3] = r1\n",
    "        df.iat[i,4] = r2\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n"
     ]
    }
   ],
   "source": [
    "def f(**kwargs):\n",
    "    print(*kwargs.values())\n",
    "\n",
    "f(z=1, a=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path = '/content/drive/MyDrive/D2NN/trained_model/20220802_*'\n",
    "files = glob.glob(path)\n",
    "p = re.compile(r'\\d+_\\d+')\n",
    "files.sort(reverse=False, key=lambda s: int(p.search(s).group()))\n",
    "acc_list = []\n",
    "for path in files:\n",
    "  model = tf.keras.models.load_model(path)\n",
    "  acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "  bi_model = tf.keras.models.load_model(path)\n",
    "  pattern = r'mo'\n",
    "  mo_layers = []\n",
    "  save = False\n",
    "  each_save = False\n",
    "  for layer in bi_model.layers:\n",
    "      result = re.match(pattern, layer.name)\n",
    "      if result:\n",
    "          mo_layers.append(layer)\n",
    "\n",
    "  for layer in mo_layers:\n",
    "      w = layer.get_weights()\n",
    "      bi_w = np.where(w[0]>0, np.pi/2, -np.pi/2)\n",
    "      w[0] = bi_w\n",
    "      layer.set_weights(w)\n",
    "\n",
    "  bi_acc = bi_model.evaluate(x_test, y_test)\n",
    "  acc_list.append([acc[1], bi_acc[1]])"
   ],
   "metadata": {
    "id": "eWTPq14bwnwN",
    "outputId": "cd310f51-6dfd-4553-9367-66798380b9a2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2448 - accuracy: 0.6352\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2484 - accuracy: 0.6128\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2115 - accuracy: 0.6498\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 1.2180 - accuracy: 0.6300\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1889 - accuracy: 0.6562\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.1967 - accuracy: 0.6370\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2095 - accuracy: 0.6526\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2098 - accuracy: 0.6377\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2304 - accuracy: 0.6536\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2391 - accuracy: 0.6301\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2465 - accuracy: 0.6455\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2551 - accuracy: 0.6292\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2351 - accuracy: 0.6649\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2488 - accuracy: 0.6419\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2346 - accuracy: 0.6649\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.2677 - accuracy: 0.6334\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(acc_list)\n",
    "df.to_csv(\"acc.csv\")"
   ],
   "metadata": {
    "id": "v4s5qYXqxFfA"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 最適化"
   ],
   "metadata": {
    "id": "3gKZ2kx91toz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install GPyOpt"
   ],
   "metadata": {
    "id": "Xh8LgS4S1hkF",
    "outputId": "11caa631-6ae6-4239-8008-506016686a9d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting GPyOpt\n",
      "  Downloading GPyOpt-1.2.6.tar.gz (56 kB)\n",
      "\u001B[K     |████████████████████████████████| 56 kB 3.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from GPyOpt) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from GPyOpt) (1.7.3)\n",
      "Collecting GPy>=1.8\n",
      "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
      "\u001B[K     |████████████████████████████████| 959 kB 13.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from GPy>=1.8->GPyOpt) (1.15.0)\n",
      "Collecting paramz>=0.9.0\n",
      "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
      "\u001B[K     |████████████████████████████████| 71 kB 10.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from GPy>=1.8->GPyOpt) (0.29.31)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt) (4.4.2)\n",
      "Building wheels for collected packages: GPyOpt, GPy, paramz\n",
      "  Building wheel for GPyOpt (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for GPyOpt: filename=GPyOpt-1.2.6-py3-none-any.whl size=83609 sha256=08dc41a0daae960a08873a1fc3b5920f92fde5f6829c8358b61913b8297e11a5\n",
      "  Stored in directory: /root/.cache/pip/wheels/e6/fa/d1/f9652b5af79f769a0ab74dbead7c7aea9a93c6bc74543fd3ec\n",
      "  Building wheel for GPy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for GPy: filename=GPy-1.10.0-cp37-cp37m-linux_x86_64.whl size=2565116 sha256=6074b4fbaa7e1b25b6b4468eab041fdb4669e3fefbc033b88f1d4888b9c7da3c\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/18/28/dd1ce0192a81b71a3b086fd952511d088b21e8359ea496860a\n",
      "  Building wheel for paramz (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102566 sha256=f73eaaa23796fd89dbcf1bb984773b519234d82017dfcba4825ef78439a05740\n",
      "  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\n",
      "Successfully built GPyOpt GPy paramz\n",
      "Installing collected packages: paramz, GPy, GPyOpt\n",
      "Successfully installed GPy-1.10.0 GPyOpt-1.2.6 paramz-0.9.5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import GPy\n",
    "import GPyOpt"
   ],
   "metadata": {
    "id": "vGjlpsbo1swM",
    "outputId": "7b6f8244-4617-476c-8b02-ccce40a8e806",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorFlow: 2.8.2\n",
      "Python: 3.7.13 (default, Apr 24 2022, 01:04:09) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(**kwargs):\n",
    "    z = kwargs[\"z\"]\n",
    "    r1 = kwargs[\"r1\"]\n",
    "    r2 = kwargs[\"r2\"]\n",
    "    wavelength = 532.0e-9\n",
    "    d = 1.0e-6\n",
    "    n = 1.5\n",
    "    #tf.random.set_seed(kwargs[\"seed\"])\n",
    "    shape = (100, 100)\n",
    "    inputs = tf.keras.Input((28, 28))\n",
    "    theta = -2.79 * np.pi / 180\n",
    "    eta = np.arctan(1.24 * np.pi/180)/2\n",
    "    l1=1.0e-5\n",
    "    print(kwargs)\n",
    "    x = ImageResizing(shape)(inputs)\n",
    "    x = ImageBinarization(0.5, 0.0, 1.0)(x)\n",
    "    x = IntensityToElectricField(shape)(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.ShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=0.7e-3, d=d, n=1.51, method='expand')(x)\n",
    "    x = MO(shape, limitation='sin', theta=theta, eta=eta, kernel_regularizer=regularizer.ShiftL1Regularizer(l1, np.pi/2))(x)\n",
    "    x = AngularSpectrum(shape, wavelength=wavelength, z=z, d=d, n=1.00, method='expand')(x)\n",
    "    # x = Polarizer(shape)(x)\n",
    "    #x =ElectricFieldToIntensity(shape)(x)\n",
    "    #x = MNISTFilter(shape)(x)\n",
    "    x = FaradayRotationByStokes(shape)(x)\n",
    "    # x = Argument(shape)(x)\n",
    "    #x = MNISTDetector(10)(x)\n",
    "    x = CircleOnCircumferenceDetector(10, r1, r2)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ],
   "metadata": {
    "id": "QUeL4Qvi16MN"
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = []"
   ],
   "metadata": {
    "id": "aEkxLUtY_8QC"
   },
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "count = 0\n",
    "def train(**kwargs):\n",
    "    global count\n",
    "    count += 1\n",
    "    model = create_model(**kwargs)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,  # category: sparse_categorical_crossentropy\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs = 50\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='accuracy',\n",
    "        min_delta=0.05,\n",
    "        patience=2,\n",
    "    )\n",
    "\n",
    "    model_name = \"20220802_BO/\" + str(count)\n",
    "    cholab_path = \"/content/drive/MyDrive/D2NN/\"\n",
    "    checkpoint_path = cholab_path + \"checkpoint/\" + model_name + \"/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # チェックポイントコールバックを作る\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "\n",
    "    logdir = os.path.join(cholab_path +\"logs\", model_name)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    result = model.fit(x_train,\n",
    "                       y_train,\n",
    "                       batch_size=64,\n",
    "                       epochs=epochs,\n",
    "                       validation_data=(x_val, y_val),\n",
    "                       callbacks=[cp_callback, tensorboard_callback]\n",
    "                       )\n",
    "\n",
    "    path = cholab_path + \"trained_model/\"+ model_name\n",
    "    model.save(path)\n",
    "\n",
    "    df = pd.DataFrame(result.history)\n",
    "    df.to_csv(path + \"/history.csv\")\n",
    "\n",
    "    with open(path + \"/config.json\", 'w') as f:\n",
    "        json.dump(model.get_config(), f, indent=4)\n",
    "\n",
    "    bi_model = tf.keras.models.load_model(path)\n",
    "    pattern = r'mo'\n",
    "    mo_layers = []\n",
    "    for layer in bi_model.layers:\n",
    "        result = re.match(pattern, layer.name)\n",
    "        if result:\n",
    "            mo_layers.append(layer)\n",
    "\n",
    "    for layer in mo_layers:\n",
    "        w = layer.get_weights()\n",
    "        bi_w = np.where(w[0]>0, np.pi/2, -np.pi/2)\n",
    "        w[0] = bi_w\n",
    "        layer.set_weights(w)\n",
    "    evaluate = bi_model.evaluate(x_test, y_test)\n",
    "    history.append([count, *kwargs, evaluate[0], evaluate[1]])\n",
    "    df = pd.DataFrame(history)\n",
    "    df.to_csv(\"/content/drive/MyDrive/D2NN/trained_model/20220802_BO/bo_history.csv\")\n",
    "\n",
    "    return evaluate"
   ],
   "metadata": {
    "id": "XbyyY3d41142"
   },
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bounds = [{'name': 'z',  'type': 'continuous',  'domain': (0.1e-3, 5.0e-3)},\n",
    "          {'name': 'r1', 'type': 'discrete',  'domain': range(1,50)},\n",
    "          {'name': 'r2', 'type': 'discrete',  'domain': range(1,50)}]\n",
    "\n",
    "constraints = [\n",
    "    {\n",
    "        \"name\": \"constr_1\",\n",
    "        \"constraint\": \"(x[:,1] + x[:,2]) - 50\" # r1 + r2 <= 50\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"constr_2\",\n",
    "        \"constraint\": \"x[:,1]*0.325 - x[:,2]\" # r2 >= r1*tan(2pi/10)\n",
    "    }\n",
    "]\n",
    "\n",
    "# ベイズ最適化する関数（上記で書いたブラックボックス）を定義します。\n",
    "# xが入力で、出力はreturnされます。\n",
    "def f(x):\n",
    "    print(x)\n",
    "    evaluation = train(\n",
    "        z = float(x[:,0]),\n",
    "        r1 = float(x[:,1]),\n",
    "        r2 = int(x[:,2]))\n",
    "    print(\"loss:{0} \\t\\t accuracy:{1}\".format(evaluation[0], evaluation[1]))\n",
    "    print(evaluation)\n",
    "    return evaluation[0]\n",
    "\n",
    "# 事前探索を行います。\n",
    "opt_mnist = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds, constraints=constraints)\n",
    "\n",
    "# 最適なパラメータを探索します。\n",
    "opt_mnist.run_optimization(max_iter=20)\n",
    "print(\"optimized parameters: {0}\".format(opt_mnist.x_opt))\n",
    "print(\"optimized loss: {0}\".format(opt_mnist.fx_opt))"
   ],
   "metadata": {
    "id": "Zxjd2OQU5PpS",
    "outputId": "a555b1d3-ca5e-4189-c81f-50d50d361218",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.00493996 3.         1.        ]]\n",
      "{'z': 0.004939963658902567, 'r1': 3.0, 'r2': 1}\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " image_resizing_25 (ImageRes  (None, 100, 100)         0         \n",
      " izing)                                                          \n",
      "                                                                 \n",
      " image_binarization_25 (Imag  (None, 100, 100)         0         \n",
      " eBinarization)                                                  \n",
      "                                                                 \n",
      " intensity_to_electric_field  (None, 2, 100, 100)      0         \n",
      " _25 (IntensityToElectricFie                                     \n",
      " ld)                                                             \n",
      "                                                                 \n",
      " mo_50 (MO)                  (None, 2, 100, 100)       10000     \n",
      "                                                                 \n",
      " angular_spectrum_50 (Angula  (None, 2, 100, 100)      0         \n",
      " rSpectrum)                                                      \n",
      "                                                                 \n",
      " mo_51 (MO)                  (None, 2, 100, 100)       10000     \n",
      "                                                                 \n",
      " angular_spectrum_51 (Angula  (None, 2, 100, 100)      0         \n",
      " rSpectrum)                                                      \n",
      "                                                                 \n",
      " faraday_rotation_by_stokes_  (None, 100, 100)         0         \n",
      " 24 (FaradayRotationByStokes                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " circle_on_circumference_det  (None, 10)               0         \n",
      " ector (CircleOnCircumferenc                                     \n",
      " eDetector)                                                      \n",
      "                                                                 \n",
      " softmax_23 (Softmax)        (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,000\n",
      "Trainable params: 20,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "858/860 [============================>.] - ETA: 0s - loss: 2.5167 - accuracy: 0.1238\n",
      "Epoch 1: saving model to /content/drive/MyDrive/D2NN/checkpoint/20220802_BO/1/cp-0001.ckpt\n",
      "860/860 [==============================] - 16s 17ms/step - loss: 2.5166 - accuracy: 0.1238 - val_loss: 2.4323 - val_accuracy: 0.1138\n",
      "Epoch 2/50\n",
      "857/860 [============================>.] - ETA: 0s - loss: 2.3529 - accuracy: 0.1118"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "20220802.ipynb",
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

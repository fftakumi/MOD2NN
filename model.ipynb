{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3jmBkPqV5FrH",
    "outputId": "cdd231d8-b289-4374-b03c-10fcc806ff40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.0.0\n",
      "Python: 3.6.13 |Anaconda, Inc.| (default, Feb 23 2021, 12:58:59) \n",
      "[GCC Clang 10.0.0 ]\n",
      "OpenCV: 3.4.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape : ((rcp or lcp), (real, image), width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XHZMEAtt5FrK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class InputToCx(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim):\n",
    "        super(InputToCx, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        rcp_real = inputs * tf.cos(0.0)\n",
    "        rcp_imag = inputs * tf.sin(0.0)\n",
    "        rcp = (1.0 / 2.0) * tf.stack([rcp_real, rcp_imag], axis=1)\n",
    "\n",
    "        lcp_real = inputs * tf.cos(0.0)\n",
    "        lcp_imag = inputs * tf.sin(0.0)\n",
    "        lcp = (1.0 / 2.0) * tf.stack([lcp_real, lcp_imag], axis=1)\n",
    "        return tf.stack([rcp, lcp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BtQrEn-p5FrM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CxMO(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim):\n",
    "        super(CxMO, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    # input[0,:,:] = real\n",
    "    # input[1,:,:] = image\n",
    "    def build(self, input_dim):\n",
    "        self.phi = self.add_variable(\"phi\",\n",
    "                                     shape=[int(input_dim[-2]),\n",
    "                                            int(input_dim[-1])])\n",
    "\n",
    "        super(CxMO, self).build(input_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x_rcp_real = Lambda(lambda x: x[:, 0, 0, :, :], output_shape=self.output_dim)(x)  # rcp real\n",
    "        x_rcp_imag = Lambda(lambda x: x[:, 0, 1, :, :], output_shape=self.output_dim)(x)  # rcp image\n",
    "\n",
    "        x_lcp_real = Lambda(lambda x: x[:, 1, 0, :, :], output_shape=self.output_dim)(x)  # lcp real\n",
    "        x_lcp_imag = Lambda(lambda x: x[:, 1, 1, :, :], output_shape=self.output_dim)(x)  # lcp image\n",
    "\n",
    "        mo_real = tf.cos(self.phi)\n",
    "        mo_imag = tf.sin(self.phi)\n",
    "\n",
    "        rcp_real = x_rcp_real * mo_real - x_rcp_imag * mo_imag\n",
    "        rcp_imag = x_rcp_real * mo_imag + x_rcp_imag * mo_real\n",
    "\n",
    "        lcp_real = x_lcp_real * mo_real - x_lcp_imag * mo_imag\n",
    "        lcp_imag = x_lcp_real * mo_imag + x_lcp_imag * mo_real\n",
    "\n",
    "        rcp = tf.stack([rcp_real, rcp_imag], axis=1)\n",
    "        lcp = tf.stack([lcp_real, lcp_imag], axis=1)\n",
    "\n",
    "        cmpx = tf.stack([rcp, lcp], axis=1)\n",
    "        return cmpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RTiCLsir5FrN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FreeSpacePropagation(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, k, z, input_pitch=1e-6, output_pitch=1e-6, normalization=None):\n",
    "        super(FreeSpacePropagation, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.input_pitch = input_pitch\n",
    "        self.output_pitch = output_pitch\n",
    "        self.z = z\n",
    "        self.k = k\n",
    "        self.normalization = normalization\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        x1 = np.arange(0, input_shape[-1], 1)\n",
    "        y1 = np.arange(0, input_shape[-2], 1)\n",
    "        xx1, yy1 = np.meshgrid(x1, y1)\n",
    "        xx1 = xx1.reshape(-1, 1) - input_shape[-1] / 2\n",
    "        yy1 = yy1.reshape(-1, 1) - input_shape[-2] / 2\n",
    "\n",
    "        x2 = np.arange(0, self.output_dim[1], 1)\n",
    "        y2 = np.arange(0, self.output_dim[0], 1)\n",
    "        xx2, yy2 = np.meshgrid(x2, y2)\n",
    "        xx2 = xx2.reshape(1, -1) - self.output_dim[1] / 2\n",
    "        yy2 = yy2.reshape(1, -1) - self.output_dim[0] / 2\n",
    "\n",
    "        dx = (self.output_pitch * xx2 - self.input_pitch * xx1)\n",
    "        dy = (self.output_pitch * yy2 - self.input_pitch * yy1)\n",
    "        r = np.sqrt(dx ** 2 + dy ** 2 + self.z ** 2)\n",
    "        w = 1 / (2 * np.pi) * self.z / r * (1 / r - 1j * self.k) * np.exp(1j * self.k * r)\n",
    "\n",
    "        self.w_real = tf.Variable(initial_value=w.real.astype('float32'),\n",
    "                                  trainable=False)\n",
    "        self.w_imag = tf.Variable(initial_value=w.imag.astype('float32'),\n",
    "                                  trainable=False)\n",
    "\n",
    "        super(FreeSpacePropagation, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        x_rcp_real = Lambda(lambda x: x[:, 0, 0, :, :], output_shape=(self.output_dim,))(x)\n",
    "        x_rcp_imag = Lambda(lambda x: x[:, 0, 1, :, :], output_shape=(self.output_dim,))(x)\n",
    "        x_lcp_real = Lambda(lambda x: x[:, 1, 0, :, :], output_shape=(self.output_dim,))(x)\n",
    "        x_lcp_imag = Lambda(lambda x: x[:, 1, 1, :, :], output_shape=(self.output_dim,))(x)\n",
    "\n",
    "        x_rcp_real = tf.reshape(x_rcp_real, (-1, x.shape[-1] * x.shape[-2]))\n",
    "        x_rcp_imag = tf.reshape(x_rcp_imag, (-1, x.shape[-1] * x.shape[-2]))\n",
    "        x_lcp_real = tf.reshape(x_lcp_real, (-1, x.shape[-1] * x.shape[-2]))\n",
    "        x_lcp_imag = tf.reshape(x_lcp_imag, (-1, x.shape[-1] * x.shape[-2]))\n",
    "\n",
    "        rcp_real = tf.matmul(x_rcp_real, self.w_real) - tf.matmul(x_rcp_imag, self.w_imag)\n",
    "        rcp_imag = tf.matmul(x_rcp_imag, self.w_real) - tf.matmul(x_rcp_real, self.w_imag)\n",
    "        lcp_real = tf.matmul(x_lcp_real, self.w_real) - tf.matmul(x_lcp_imag, self.w_imag)\n",
    "        lcp_imag = tf.matmul(x_lcp_imag, self.w_real) - tf.matmul(x_lcp_real, self.w_imag)\n",
    "\n",
    "        rcp_real = tf.reshape(rcp_real, (-1, self.output_dim[0], self.output_dim[1]))\n",
    "        rcp_imag = tf.reshape(rcp_imag, (-1, self.output_dim[0], self.output_dim[1]))\n",
    "        lcp_real = tf.reshape(lcp_real, (-1, self.output_dim[0], self.output_dim[1]))\n",
    "        lcp_imag = tf.reshape(lcp_imag, (-1, self.output_dim[0], self.output_dim[1]))\n",
    "\n",
    "        rcp = tf.stack([rcp_real, rcp_imag], axis=1)\n",
    "        lcp = tf.stack([lcp_real, lcp_imag], axis=1)\n",
    "\n",
    "        cmpx = tf.stack([rcp, lcp], axis=1)\n",
    "\n",
    "        if self.normalization == 'max':\n",
    "            absmax = tf.reduce_max(tf.abs(cmpx))\n",
    "            cmpx = cmpx / absmax\n",
    "\n",
    "        return cmpx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "8nG7x1gC5FrO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CxD2NNIntensity(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, normalization='min_max', **kwargs):\n",
    "        super(CxD2NNIntensity, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.normalization = normalization\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        x_rcp_real = Lambda(lambda x: x[:,0, 0, :, :])(x)\n",
    "        x_rcp_imag = Lambda(lambda x: x[:,0, 1, :, :])(x)\n",
    "        x_lcp_real = Lambda(lambda x: x[:,1, 0, :, :])(x)\n",
    "        x_lcp_imag = Lambda(lambda x: x[:,1, 1, :, :])(x)\n",
    "        i_rcp = tf.sqrt(x_rcp_real ** 2 + x_rcp_imag ** 2)\n",
    "        i_lcp = tf.sqrt(x_lcp_real ** 2 + x_lcp_imag ** 2)\n",
    "        intensity = (i_rcp + i_lcp) / 2\n",
    "        if self.normalization == 'min_max':\n",
    "            max = tf.reduce_max(intensity)\n",
    "            min = tf.reduce_min(intensity)\n",
    "            intensity = (intensity - min) / (max - min)\n",
    "        if self.normalization == 'max':\n",
    "            max = tf.reduce_max(intensity)\n",
    "            intensity = intensity / max\n",
    "\n",
    "        return intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class CxD2NNEllipticity(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super(CxD2NNEllipticity, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        x_rcp_real = Lambda(lambda x: x[:,0, 0, :, :])(x)\n",
    "        x_rcp_imag = Lambda(lambda x: x[:,0, 1, :, :])(x)\n",
    "        x_lcp_real = Lambda(lambda x: x[:,1, 0, :, :])(x)\n",
    "        x_lcp_imag = Lambda(lambda x: x[:,1, 1, :, :])(x)\n",
    "        i_rcp = tf.sqrt(x_rcp_real ** 2 + x_rcp_imag ** 2)\n",
    "        i_lcp = tf.sqrt(x_lcp_real ** 2 + x_lcp_imag ** 2)\n",
    "        ellipticity = (i_rcp - i_lcp)/(i_rcp + i_lcp)\n",
    "\n",
    "        return ellipticity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CxD2NNMNISTDetector(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, activation=None, **kwargs):\n",
    "        super(CxD2NNMNISTDetector, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_dim = input_shape\n",
    "        self.width = min(int(tf.floor(self.input_dim[2] / 9.0)), int(tf.floor(self.input_dim[1] / 7.0)))\n",
    "        self.height = min(int(tf.floor(self.input_dim[2] / 9.0)), int(tf.floor(self.input_dim[1] / 7.0)))\n",
    "        super(CxD2NNMNISTDetector, self).build(input_shape)\n",
    "\n",
    "    def plot_area(self, input_shape, same_color=False):\n",
    "        width = min(int(np.floor(input_shape[1] / 9.0)), int(np.floor(input_shape[0] / 7.0)))\n",
    "        height = min(int(np.floor(input_shape[1] / 9.0)), int(np.floor(input_shape[0] / 7.0)))\n",
    "        x = np.zeros(input_shape)\n",
    "        if same_color:\n",
    "            x[2 * height:3 * height, width:2 * width] = 1\n",
    "            x[2 * height:3 * height, 4 * width:5 * width] = 1\n",
    "            x[2 * height:3 * height, 7 * width:8 * width] = 1\n",
    "            x[4 * height:5 * height, 1 * width:2 * width] = 1\n",
    "            x[4 * height:5 * height, 3 * width:4 * width] = 1\n",
    "            x[4 * height:5 * height, 5 * width:6 * width] = 1\n",
    "            x[4 * height:5 * height, 7 * width:8 * width] = 1\n",
    "            x[6 * height:7 * height, width:2 * width] = 1\n",
    "            x[6 * height:7 * height, 4 * width:5 * width] = 1\n",
    "            x[6 * height:7 * height, 7 * width:8 * width] = 1\n",
    "        else:\n",
    "            x[2 * height:3 * height, width:2 * width] = 1\n",
    "            x[2 * height:3 * height, 4 * width:5 * width] = 2\n",
    "            x[2 * height:3 * height, 7 * width:8 * width] = 3\n",
    "            x[4 * height:5 * height, 1 * width:2 * width] = 4\n",
    "            x[4 * height:5 * height, 3 * width:4 * width] = 5\n",
    "            x[4 * height:5 * height, 5 * width:6 * width] = 6\n",
    "            x[4 * height:5 * height, 7 * width:8 * width] = 7\n",
    "            x[6 * height:7 * height, width:2 * width] = 8\n",
    "            x[6 * height:7 * height, 4 * width:5 * width] = 9\n",
    "            x[6 * height:7 * height, 7 * width:8 * width] = 10\n",
    "        plt.imshow(x)\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        y0 = x[:, 2 * self.height:3 * self.height, self.width:2 * self.width]\n",
    "        y1 = x[:, 2 * self.height:3 * self.height, 4 * self.width:5 * self.width]\n",
    "        y2 = x[:, 2 * self.height:3 * self.height, 7 * self.width:8 * self.width]\n",
    "        y3 = x[:, 4 * self.height:5 * self.height, self.width:2 * self.width]\n",
    "        y4 = x[:, 4 * self.height:5 * self.height, 3 * self.width:4 * self.width]\n",
    "        y5 = x[:, 4 * self.height:5 * self.height, 5 * self.width:6 * self.width]\n",
    "        y6 = x[:, 4 * self.height:5 * self.height, 7 * self.width:8 * self.width]\n",
    "        y7 = x[:, 6 * self.height:7 * self.height, self.width:2 * self.width]\n",
    "        y8 = x[:, 6 * self.height:7 * self.height, 4 * self.width:5 * self.width]\n",
    "        y9 = x[:, 6 * self.height:7 * self.height, 7 * self.width:8 * self.width]\n",
    "        y0 = tf.reduce_sum(y0, axis=[1])\n",
    "        y0 = tf.reduce_sum(y0, axis=[1], keepdims=True)\n",
    "        y1 = tf.reduce_sum(y1, axis=[1])\n",
    "        y1 = tf.reduce_sum(y1, axis=[1], keepdims=True)\n",
    "        y2 = tf.reduce_sum(y2, axis=[1])\n",
    "        y2 = tf.reduce_sum(y2, axis=[1], keepdims=True)\n",
    "        y3 = tf.reduce_sum(y3, axis=[1])\n",
    "        y3 = tf.reduce_sum(y3, axis=[1], keepdims=True)\n",
    "        y4 = tf.reduce_sum(y4, axis=[1])\n",
    "        y4 = tf.reduce_sum(y4, axis=[1], keepdims=True)\n",
    "        y5 = tf.reduce_sum(y5, axis=[1])\n",
    "        y5 = tf.reduce_sum(y5, axis=[1], keepdims=True)\n",
    "        y6 = tf.reduce_sum(y6, axis=[1])\n",
    "        y6 = tf.reduce_sum(y6, axis=[1], keepdims=True)\n",
    "        y7 = tf.reduce_sum(y7, axis=[1])\n",
    "        y7 = tf.reduce_sum(y7, axis=[1], keepdims=True)\n",
    "        y8 = tf.reduce_sum(y8, axis=[1])\n",
    "        y8 = tf.reduce_sum(y8, axis=[1], keepdims=True)\n",
    "        y9 = tf.reduce_sum(y9, axis=[1])\n",
    "        y9 = tf.reduce_sum(y9, axis=[1], keepdims=True)\n",
    "        y = tf.keras.layers.concatenate([y0, y1, y2, y3, y4, y5, y6, y7, y8, y9])\n",
    "\n",
    "        if self.activation == 'softmax':\n",
    "            y = tf.nn.softmax(y)\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Dpt-HgVUOdqH"
   },
   "outputs": [],
   "source": [
    "def create_true_mnistimage(label, shape):\n",
    "    width = min(int(np.floor(shape[1] / 9.0)), int(np.floor(shape[0] / 7.0)))\n",
    "    height = min(int(np.floor(shape[1] / 9.0)), int(np.floor(shape[0] / 7.0)))\n",
    "    x = np.zeros(shape)\n",
    "\n",
    "    if label == 0:\n",
    "        x[2 * height:3 * height, width:2 * width] = 1.0\n",
    "    elif label == 1:\n",
    "        x[2 * height:3 * height, 4 * width:5 * width] = 1.0\n",
    "    elif label == 2:\n",
    "        x[2 * height:3 * height, 7 * width:8 * width] = 1.0\n",
    "    elif label == 3:\n",
    "        x[4 * height:5 * height, 1 * width:2 * width] = 1.0\n",
    "    elif label == 4:\n",
    "        x[4 * height:5 * height, 3 * width:4 * width] = 1.0\n",
    "    elif label == 5:\n",
    "        x[4 * height:5 * height, 5 * width:6 * width] = 1.0\n",
    "    elif label == 6:\n",
    "        x[4 * height:5 * height, 7 * width:8 * width] = 1.0\n",
    "    elif label == 7:\n",
    "        x[6 * height:7 * height, width:2 * width] = 1.0\n",
    "    elif label == 8:\n",
    "        x[6 * height:7 * height, 4 * width:5 * width] = 1.0\n",
    "    elif label == 9:\n",
    "        x[6 * height:7 * height, 7 * width:8 * width] = 1.0\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "RLvSiiMoOgg5",
    "outputId": "de3e31ed-5c89-4423-c025-94b9a62ce841"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fb45bd33240>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAEFCAYAAADqlvKRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPtklEQVR4nO3df6zddX3H8edLfrSUZjJDl9mSqcEATgUmraMhcwyIwzWBRLPEGcyYQmMmGJkxgeFAK1kJi2AUdFaMG04XRZGFhFjEpYwNCDasyhAYKKDSyGBj/GqKIO/9cb53uZ/r95Zz23N6z8HnIzn53Pv5fL7n++kn97z6/Xy/n9umqpCkGS9b7AFImiyGgqSGoSCpYShIahgKkhqGgqSGoSCpMZZQSPKyJOckuSfJziQ/SfKJJAeO43ySRmdcVwqXAZcCPwDOBq4GPgBcl8SrE2mC7TvqN0zyegZBcE1VvWNW/QPAp4B3Al8Z9XkljUZGvc05yUXA+cBbqurmWfVLgf8GbqqqP9rVe+yfJbUUVxrSOD3F449V1Yq59SO/UgDWAC8At8+urKqdSbZ17bu0lAP53Zw4hqFJmnFjff2hvvpxrO9XAo9V1bM9bQ8DByfZfwznlTQC4wiFZUBfIADsnNWnkWR9kq1Jtj437+GSxm0cobADWDJP29JZfRpVtamqVlfV6v3mPVzSuI0jFLYzWCL0fbJXMVha/HwM55U0AuMIhe927/vm2ZXd04ejga1jOKekERlHKHwVKOCDc+rPZHAv4ctjOKekERn5I8mqujPJFcBZSa4Brgdex2BH4024cUmaaOPYpwCDq4QHgfXAOuAx4NPABVX1wpjOKWkExhIKVfUL4BPdS9IU8ZeTJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUmNoUIhyXlJrk7yoySV5MEX6X94kmuTPJ7kmSQ3JzlhJCOWNFb7Dtnvr4H/Ae4ADtpVxySHArcAzwOXAE8AZwKbk7ytqm7c7dFKGrthQ+HQqvoRQJL/AJbvou9GBsFxTFVt6465CrgLuCLJEVVVuz1iSWM11PJhJhBeTJIDgVOALTOB0B3/NHAlcBiwZuHDlLS3jPpG45HAEuDWnrbbutJQkCbYsMuHYa3syod72mbqVvUdmGQ9sB5gKctGPCxJwxr1lcLMp/nZnradc/o0qmpTVa2uqtX7sWTEw5I0rFGHwo6u7PtUL53TR9IEGnUobO/KviXCTF3f0kLShBh1KNzJYOmwtqft2K7cOuJzShqhkYZC9+jxOuD4JEfN1CdZDpwB3AfcPspzShqtoZ4+JHk38Kru2xXA/kk+0n3/UFV9aVb384ATgRuSXAY8yWBH4ypgnRuXpMk27CPJ9wK/P6fu4115E/D/oVBV9yc5DrgYOBfYn8H26JPd4ixNvqFCoaqOX8ibVtXdwKm7MyBJi8tfnZbUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUGCoUkhyWZEOS25I8muSpJNuSnJ/kwJ7+hye5NsnjSZ5JcnOSE0Y/fEmjNuyVwnuAc4AfAhuADwP3AhcBtyQ5YKZjkkOBW4C1wCVd3+XA5iQnjW7oksZh3yH7fR3YWFVPzKr72yT3AecD7wUu7+o3AgcBx1TVNoAkVwF3AVckOaKqagRjlzQGQ10pVNXWOYEw46td+QaAbilxCrBlJhC6458GrgQOA9bsyYAljdee3mg8pCsf6cojgSXArT19b+tKQ0GaYLsdCkn2AS4Ange+0lWv7MqHew6ZqVu1u+eUNH7D3lPo80ngWOAvq+rerm5ZVz7b03/nnD6NJOuB9QBL+7tI2gt260ohyceBs4BNVbVxVtOOrlzSc9jSOX0aVbWpqlZX1er9eg+XtDcsOBSSfBT4CPBF4H1zmrd3Zd8SYaaub2khaUIsKBSSXAhcCFwFnNHzaPFOBkuHtT2HH9uVWxc6SEl7z9ChkOQC4KPAl4A/q6oX5vbpHj1eBxyf5KhZxy4HzgDuA27fwzFLGqOhbjQmeT/wMeDHwI3Au5LM7vJIVX27+/o84ETghiSXAU8CZzJYPqxz45I02YZ9+jCzt+C3gL/vab8J+DZAVd2f5DjgYuBcYH/gDuDkqrpxz4YradyGCoWqOh04fdg3raq7gVN3b0iSFpO/Oi2pYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIagwVCkkOT/LlJHcneSLJjiT3JLk0ySvn6X9tkseTPJPk5iQnjH74kkZt3yH7HQK8Evgm8FPgeeCNwHrgnUmOrqr/AkhyKHBL1+cS4AngTGBzkrdV1Y2j/SNIGqWhQqGqvgN8Z259kn8BvgacziAAADYCBwHHVNW2rt9VwF3AFUmOqKra04FLGo9hrxTm81BX/jpAkgOBU4AtM4EAUFVPJ7kS2ACsAW7fw/NKe2Tz9m0jf88/XHn0yN9zMSzoRmOSpUkOTnJIkrcCn+uaru/KI4ElwK09h9/WlWt2a6SS9oqFPn04A3gU+AmwmcEy4bSqurlrX9mVD/ccO1O3qu+Nk6xPsjXJ1ud4doHDkjQqC10+XAvcAywHfofBUmHFrPZlXdn3qd45p0+jqjYBmwB+La/wnoO0SBYUClX1UwZPHwCuTfIN4LtJDqiqjcCOrm1Jz+FLu3JHT5ukCbFHm5eq6vvAvwN/3lVt78q+JcJMXd/SQtKEGMWOxgOAV3Rf38lg6bC2p9+xXbl1BOeUNCbD7mj8zXnq/wB4A92Thap6GrgOOD7JUbP6LWdwk/I+fBwpTbRh7yl8ttvO/M8M9iYsBY4B3gk8BXxoVt/zgBOBG5JcBjzJYEfjKmCdG5ekyTZsKPwj8KfAuxk8bSgG4fA54G+q6sczHavq/iTHARcD5wL7A3cAJ7vFWZp8w25z/hqD7cxDqaq7gVN3d1CSFo+/Oi2pYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhp7+q85S1PppfIvL4+DVwqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGrsVCkmWJXkgSSW5vKf98CTXJnk8yTNJbk5ywp4PV9K47e6Vwgbg4L6GJIcCtwBrgUuADwPLgc1JTtrN80naSxYcCkneBHwQuHCeLhuBg4A/rKqNVfUZ4PeA7cAVSbJ7Q5W0NywoFJLsA3we+BZwTU/7gcApwJaq2jZTX1VPA1cChwFr9mC8ksZsoVcK5wBHAGfN034ksAS4tafttq40FKQJNnQoJHkN8DFgQ1U9OE+3lV35cE/bTN2qed5/fZKtSbY+x7PDDkvSiC3kSuGzwAPApbvos6wr+z7VO+f0aVTVpqpaXVWr92PJAoYlaZSG+s9gkpwGvBV4S1U9t4uuO7qy71O9dE4fSRPoRUMhyRIGVwfXAz9L8tquaWYZ8PKu7jEGTxhmt802U9e3tJA0IYZZPhwArADWAffNem3p2k/rvj8DuJPB0mFtz/sc25Vbd3+4ksZtmOXDM8Af99SvAD7D4PHkF4DvV9XTSa4D3p7kqKr6HkCS5QxC4z7g9pGMXNJYvGgodPcQvj63Psmruy9/WFWz288DTgRuSHIZ8CRwJoPlw7qqqj0dtKTxGfn/Ol1V9yc5DrgYOBfYH7gDOLmqbhz1+SSN1m6HQrdXoXfLclXdDZy6u+8tafH4q9OSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGoaCpIahIKlhKEhqGAqSGqmqxR7DL0nyKPAQcDDw2CIP56XKuR2faZnbV1XVirmVExkKM5JsrarViz2OlyLndnymfW5dPkhqGAqSGpMeCpsWewAvYc7t+Ez13E70PQVJe9+kXylI2ssMBUmNiQuFJC9Lck6Se5LsTPKTJJ9IcuBij20aJDksyYYktyV5NMlTSbYlOb9vDpMcnuTaJI8neSbJzUlOWIyxT6Mky5I8kKSSXN7TPnXzO3GhAFwGXAr8ADgbuBr4AHBdkkkc76R5D3AO8ENgA/Bh4F7gIuCWJAfMdExyKHALsBa4pOu7HNic5KS9PO5ptYHBZqVfMrXzW1UT8wJeD7wAfGNO/dlAAe9a7DFO+gtYDby8p/6ibg7PmlX3NeAXwNGz6pYz2E16L92NaF/zzvWbgOeBv+jm9vI57VM5v5P2N++fAAE+Oaf+88AO4LS9PaBpU1Vbq+qJnqavduUbALqlxCnAlqraNuv4p4ErgcOANeMd7fRKsg+Dn8tvAdf0tE/t/E5aKKxhcKVw++zKqtoJbGNCJ3FKHNKVj3TlkcAS4Naevrd1pfM9v3OAI4Cz5mmf2vmdtFBYCTxWVc/2tD0MHJxk/708pqnX/a12AYNL3a901Su78uGeQ2bqVo15aFMpyWuAjwEbqurBebpN7fxOWigsA/oCAWDnrD5amE8CxwIXVNW9Xd3MPPbNt3O9a58FHmBwQ3w+Uzu/+y72AObYAfzGPG1LZ/XRkJJ8nMEl7qaq2jiraWYel/Qc5lzPI8lpwFuBt1TVc7voOrXzO2mhsB347SRLepYQqxgsLX6+COOaSkk+CnwE+CLwvjnN27uy7xJ2pq7v0vdXVpIlDK4Orgd+luS1XdPMfL28q3uMKZ7fSVs+fJfBmN48uzLJUuBoYOsijGkqJbkQuBC4Cjijuudhs9zJ4NJ2bc/hx3al8906AFgBrAPum/Xa0rWf1n1/BlM8vxP1C1FJ3gh8D/hmVb1jVv3ZwKeAd1fVPyzW+KZFkgsY3Aj7EnB6Vb0wT7+rgbcDb6qq73V1y4G7GPxAH94TJr+ykuwHnNrTtAL4DIPHk18Avl9V/zmt8ztRoQCQ5NMM1sDfZHCZ9joGOxr/DThhvh9wDSR5P3A58GPgrxg84p3tkar6dtf3tQwe/z7HYCfpk8CZwBuBdVW1eW+Ne5oleTWDG49XVNVZs+qnc34Xe/dUzy6xfYAPMdjx9SyDddelwPLFHts0vIC/Y7C7br7Xljn9Xwf8E/C/DG58/Stw0mL/OabpBbyanh2N0zq/E3elIGlxTdqNRkmLzFCQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1Pg/ALY1o4hFIsQAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(create_true_mnistimage(9, (50, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nIoyHqA5FrP",
    "outputId": "39292028-37cc-4253-af6e-068e2eb941c8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "image_shape = (28, 28)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.array(list(map(lambda image: cv2.resize(image, dsize=image_shape), x_train)))\n",
    "x_test = np.array(list(map(lambda image: cv2.resize(image, dsize=image_shape), x_test)))\n",
    "y_train_image = np.array(list(map(lambda y_label: create_true_mnistimage(y_label, image_shape), y_train)))\n",
    "y_test_image = np.array(list(map(lambda y_label: create_true_mnistimage(y_label, image_shape), y_test)))\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "RHqUdqQpOk1l",
    "outputId": "ac7d7a2c-e74a-45dc-e505-94dc5ddcd863"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "detector = CxD2NNMNISTDetector(10)\n",
    "detector.plot_area((28, 28), same_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KDVIT-b55FrP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss(y_hat, y):\n",
    "    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_hat, logits=y)\n",
    "\n",
    "\n",
    "def loss_MSE(y_hat, y):\n",
    "    return tf.reduce_sum((y_hat - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "s0rXpHct5FrP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "l = 633e-9\n",
    "k = 2 * np.pi / l\n",
    "d = 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "input_to_cx_12 (InputToCx)   (None, 2, 2, 28, 28)      0         \n",
      "_________________________________________________________________\n",
      "cx_mo_12 (CxMO)              (None, 2, 2, 28, 28)      784       \n",
      "_________________________________________________________________\n",
      "free_space_propagation_12 (F (None, 2, 2, 28, 28)      1229312   \n",
      "_________________________________________________________________\n",
      "cx_d2nn_ellipticity_5 (CxD2N (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 1,230,096\n",
      "Trainable params: 784\n",
      "Non-trainable params: 1,229,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input((28, 28))\n",
    "x = InputToCx((28, 28))(inputs)\n",
    "x = CxMO((28, 28))(x)\n",
    "x = FreeSpacePropagation((28, 28), k, 1.0e-4)(x)\n",
    "x = CxD2NNEllipticity((28, 28))(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(10, 28, 28)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict((x_train[:10,:,:]))\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fb4396a3780>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NiKvMSZo5FrQ",
    "outputId": "8a2d0756-5f6e-4aab-bc9f-564d253ea7ae",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "input_to_cx_1 (InputToCx)    (None, 2, 2, 28, 28)      0         \n",
      "_________________________________________________________________\n",
      "cx_mo_1 (CxMO)               (None, 2, 2, 28, 28)      784       \n",
      "_________________________________________________________________\n",
      "free_space_propagation_1 (Fr (None, 2, 2, 28, 28)      1229312   \n",
      "_________________________________________________________________\n",
      "cx_d2nn_intensity (CxD2NNInt (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "cx_d2nnmnist_detector_1 (CxD (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,230,096\n",
      "Trainable params: 784\n",
      "Non-trainable params: 1,229,312\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "19264/60000 [========>.....................] - ETA: 30s - loss: 2.6878 - accuracy: 0.1336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-18-4a3547ead140>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m                    \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m                    \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m64\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m                    \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m                    \u001B[0;31m#callbacks=[early_stopping]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m                    )\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    726\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    727\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 728\u001B[0;31m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    729\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    730\u001B[0m   def evaluate(self,\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001B[0m\n\u001B[1;32m    322\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mModeKeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    323\u001B[0m                 \u001B[0mtraining_context\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining_context\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 324\u001B[0;31m                 total_epochs=epochs)\n\u001B[0m\u001B[1;32m    325\u001B[0m             \u001B[0mcbks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_logs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_logs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining_result\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mModeKeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    326\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36mrun_one_epoch\u001B[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001B[0m\n\u001B[1;32m    121\u001B[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001B[1;32m    122\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 123\u001B[0;31m         \u001B[0mbatch_outs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexecution_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    124\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mStopIteration\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOutOfRangeError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    125\u001B[0m         \u001B[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001B[0m in \u001B[0;36mexecution_function\u001B[0;34m(input_fn)\u001B[0m\n\u001B[1;32m     84\u001B[0m     \u001B[0;31m# `numpy` translates Tensors to values in Eager mode.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m     return nest.map_structure(_non_none_constant_value,\n\u001B[0;32m---> 86\u001B[0;31m                               distributed_function(input_fn))\n\u001B[0m\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mexecution_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 457\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    458\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtracing_count\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    459\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_counter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcalled_without_tracing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    485\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    486\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 487\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    488\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    489\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1821\u001B[0m     \u001B[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1822\u001B[0m     \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1823\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1824\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1825\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   1139\u001B[0m          if isinstance(t, (ops.Tensor,\n\u001B[1;32m   1140\u001B[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001B[0;32m-> 1141\u001B[0;31m         self.captured_inputs)\n\u001B[0m\u001B[1;32m   1142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1143\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_flat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcancellation_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1222\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1223\u001B[0m       flat_outputs = forward_function.call(\n\u001B[0;32m-> 1224\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001B[0m\u001B[1;32m   1225\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1226\u001B[0m       \u001B[0mgradient_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_delayed_rewrite_functions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    509\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    510\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"executor_type\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexecutor_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"config_proto\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 511\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    512\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    513\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001B[1;32m     60\u001B[0m                                                \u001B[0mop_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m                                                num_outputs)\n\u001B[0m\u001B[1;32m     62\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(image_shape)\n",
    "x = InputToCx(image_shape)(inputs)\n",
    "x = CxMO(image_shape)(x)\n",
    "x = FreeSpacePropagation(image_shape, k, 1.0e-4, normalization='max', input_pitch=2.0e-6, output_pitch=2.0e-6)(x)\n",
    "x = CxD2NNIntensity(image_shape, normalization='max')(x)\n",
    "x = CxD2NNMNISTDetector(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, x)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=\"sparse_categorical_crossentropy\",  # category: sparse_categorical_crossentropy\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    min_delta=0.05,\n",
    "    patience=2,\n",
    ")\n",
    "\n",
    "result = model.fit(x_train,\n",
    "                   y_train,\n",
    "                   batch_size=64,\n",
    "                   epochs=epochs\n",
    "                   #callbacks=[early_stopping]\n",
    "                   )\n",
    "model.save(\"28x28_6(MO_frspc100um)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "Psxg1H6WiyKn",
    "outputId": "77cd14fe-2e39-4480-edcb-edfb3fdb5d34"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(range(1, epochs + 1), result.history['loss'], color='black', label='Loss')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax2.plot(range(1, epochs + 1), result.history['accuracy'], color='red', label='Accuracy')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "# label1と2には、凡例用に各labelのリスト情報が入る\n",
    "handler1, label1 = ax1.get_legend_handles_labels()\n",
    "handler2, label2 = ax2.get_legend_handles_labels()\n",
    "# 凡例をまとめて出力する\n",
    "ax1.legend(handler1 + handler2, label1 + label2, loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPPH451APLgm",
    "outputId": "c0917ff2-f38e-4982-b38a-6b877567bcd3"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGBtRuwC5FrQ",
    "outputId": "6683b40b-d25f-4097-c9fa-0aa616635896",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layer_name = model.layers[-2].name\n",
    "hidden_layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "hidden_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "MM6fAIqU5FrQ",
    "outputId": "d8ef8a67-f8f9-414f-b267-a00fc524d827",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num = 5\n",
    "images = x_train[0:num, :, :]\n",
    "\n",
    "preds = model.predict(images)\n",
    "pred_images = hidden_layer_model.predict(images)\n",
    "fig, axes = plt.subplots(num, 3, figsize=(7, 10))\n",
    "for i in range(num):\n",
    "    axes[i, 0].imshow(images[i, :, :])\n",
    "    axes[i, 1].imshow(pred_images[i, :, :])\n",
    "    axes[i, 2].bar(np.arange(0, 10, 1), preds[i, :], align='center')\n",
    "    axes[i, 2].set_xticks(np.arange(0, 10, 1))\n",
    "    axes[i, 2].set_ylabel('Accuracy')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsYnMu1DPVkh",
    "outputId": "d9572cf1-26d5-4224-d4e5-d312642c376c"
   },
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers[1:]]\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlTNml_9PYWA",
    "outputId": "de67727b-8dd1-46d6-eafd-879a443e3db0"
   },
   "outputs": [],
   "source": [
    "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3v-O4IwHPaoH",
    "outputId": "8052f3b4-adda-485c-fb9d-85270e17ad63"
   },
   "outputs": [],
   "source": [
    "num = 5\n",
    "images = x_train[0:num, :, :]\n",
    "activations = activation_model.predict(images)\n",
    "len(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "Fq_5Zpj5Pgeh",
    "outputId": "942b9762-a147-4113-ed97-94ea9e5ef276"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(num, len(activations) - 2, figsize=(2 * len(activations) - 1, 2 * num))\n",
    "for i in range(len(activations) - 2):\n",
    "    layer_activation = activations[i]\n",
    "    for j in range(num):\n",
    "        intensity = tf.sqrt(layer_activation[j, 0, :, :] ** 2 + layer_activation[j, 1, :, :] ** 2)\n",
    "        axes[j, i].imshow(intensity)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3jmBkPqV5FrH",
        "outputId": "f4b76055-39fb-479c-a229-308b9ce0211d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow: 2.7.0\n",
            "Python: 3.7.12 (default, Jan 15 2022, 18:48:18) \n",
            "[GCC 7.5.0]\n",
            "OpenCV: 4.1.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Lambda\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"OpenCV:\", cv2.__version__)\n",
        "\n",
        "plt.rcParams['font.size'] = 18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O18G0cPWmr_L"
      },
      "source": [
        "shape : ((rcp or lcp), (real, image), width, height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XHZMEAtt5FrK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class InputToCx(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim):\n",
        "        super(InputToCx, self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        rcp_real = inputs * tf.cos(0.0)\n",
        "        rcp_imag = inputs * tf.sin(0.0)\n",
        "        rcp = (1.0 / 2.0) * tf.stack([rcp_real, rcp_imag], axis=1)\n",
        "\n",
        "        lcp_real = inputs * tf.cos(0.0)\n",
        "        lcp_imag = inputs * tf.sin(0.0)\n",
        "        lcp = (1.0 / 2.0) * tf.stack([lcp_real, lcp_imag], axis=1)\n",
        "        return tf.stack([rcp, lcp], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BtQrEn-p5FrM",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class CxMO(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim):\n",
        "        super(CxMO, self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    # input[0,:,:] = real\n",
        "    # input[1,:,:] = image\n",
        "    def build(self, input_dim):\n",
        "        self.phi = self.add_variable(\"phi\",\n",
        "                                     shape=[int(input_dim[-2]),\n",
        "                                            int(input_dim[-1])])\n",
        "\n",
        "        super(CxMO, self).build(input_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        x_rcp_real = Lambda(lambda x: x[:, 0, 0, :, :], output_shape=self.output_dim)(x)  # rcp real\n",
        "        x_rcp_imag = Lambda(lambda x: x[:, 0, 1, :, :], output_shape=self.output_dim)(x)  # rcp image\n",
        "\n",
        "        x_lcp_real = Lambda(lambda x: x[:, 1, 0, :, :], output_shape=self.output_dim)(x)  # lcp real\n",
        "        x_lcp_imag = Lambda(lambda x: x[:, 1, 1, :, :], output_shape=self.output_dim)(x)  # lcp image\n",
        "\n",
        "        mo_real = tf.cos(self.phi)\n",
        "        mo_imag = tf.sin(self.phi)\n",
        "\n",
        "        rcp_real = x_rcp_real * mo_real - x_rcp_imag * mo_imag\n",
        "        rcp_imag = x_rcp_real * mo_imag + x_rcp_imag * mo_real\n",
        "\n",
        "        lcp_real = x_lcp_real * mo_real - x_lcp_imag * mo_imag\n",
        "        lcp_imag = x_lcp_real * mo_imag + x_lcp_imag * mo_real\n",
        "\n",
        "        rcp = tf.stack([rcp_real, rcp_imag], axis=1)\n",
        "        lcp = tf.stack([lcp_real, lcp_imag], axis=1)\n",
        "\n",
        "        cmpx = tf.stack([rcp, lcp], axis=1)\n",
        "        return cmpx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RTiCLsir5FrN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class FreeSpacePropagation(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim, k, z, input_pitch=1e-6, output_pitch=1e-6, normalization=None):\n",
        "        super(FreeSpacePropagation, self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.input_pitch = input_pitch\n",
        "        self.output_pitch = output_pitch\n",
        "        self.z = z\n",
        "        self.k = k\n",
        "        self.normalization = normalization\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        x1 = np.arange(0, input_shape[-1], 1)\n",
        "        y1 = np.arange(0, input_shape[-2], 1)\n",
        "        xx1, yy1 = np.meshgrid(x1, y1)\n",
        "        xx1 = xx1.reshape(-1, 1) - input_shape[-1] / 2\n",
        "        yy1 = yy1.reshape(-1, 1) - input_shape[-2] / 2\n",
        "\n",
        "        x2 = np.arange(0, self.output_dim[1], 1)\n",
        "        y2 = np.arange(0, self.output_dim[0], 1)\n",
        "        xx2, yy2 = np.meshgrid(x2, y2)\n",
        "        xx2 = xx2.reshape(1, -1) - self.output_dim[1] / 2\n",
        "        yy2 = yy2.reshape(1, -1) - self.output_dim[0] / 2\n",
        "\n",
        "        dx = (self.output_pitch * xx2 - self.input_pitch * xx1)\n",
        "        dy = (self.output_pitch * yy2 - self.input_pitch * yy1)\n",
        "        r = np.sqrt(dx ** 2 + dy ** 2 + self.z ** 2)\n",
        "        w = 1 / (2 * np.pi) * self.z / r * (1 / r - 1j * self.k) * np.exp(1j * self.k * r)\n",
        "\n",
        "        self.w_real = tf.Variable(initial_value=w.real.astype('float32'),\n",
        "                                  trainable=False)\n",
        "        self.w_imag = tf.Variable(initial_value=w.imag.astype('float32'),\n",
        "                                  trainable=False)\n",
        "\n",
        "        super(FreeSpacePropagation, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, **kwargs):\n",
        "        x_rcp_real = Lambda(lambda x: x[:, 0, 0, :, :], output_shape=(self.output_dim,))(x)\n",
        "        x_rcp_imag = Lambda(lambda x: x[:, 0, 1, :, :], output_shape=(self.output_dim,))(x)\n",
        "        x_lcp_real = Lambda(lambda x: x[:, 1, 0, :, :], output_shape=(self.output_dim,))(x)\n",
        "        x_lcp_imag = Lambda(lambda x: x[:, 1, 1, :, :], output_shape=(self.output_dim,))(x)\n",
        "\n",
        "        x_rcp_real = tf.reshape(x_rcp_real, (-1, x.shape[-1] * x.shape[-2]))\n",
        "        x_rcp_imag = tf.reshape(x_rcp_imag, (-1, x.shape[-1] * x.shape[-2]))\n",
        "        x_lcp_real = tf.reshape(x_lcp_real, (-1, x.shape[-1] * x.shape[-2]))\n",
        "        x_lcp_imag = tf.reshape(x_lcp_imag, (-1, x.shape[-1] * x.shape[-2]))\n",
        "\n",
        "        rcp_real = tf.matmul(x_rcp_real, self.w_real) - tf.matmul(x_rcp_imag, self.w_imag)\n",
        "        rcp_imag = tf.matmul(x_rcp_imag, self.w_real) - tf.matmul(x_rcp_real, self.w_imag)\n",
        "        lcp_real = tf.matmul(x_lcp_real, self.w_real) - tf.matmul(x_lcp_imag, self.w_imag)\n",
        "        lcp_imag = tf.matmul(x_lcp_imag, self.w_real) - tf.matmul(x_lcp_real, self.w_imag)\n",
        "\n",
        "        rcp_real = tf.reshape(rcp_real, (-1, self.output_dim[0], self.output_dim[1]))\n",
        "        rcp_imag = tf.reshape(rcp_imag, (-1, self.output_dim[0], self.output_dim[1]))\n",
        "        lcp_real = tf.reshape(lcp_real, (-1, self.output_dim[0], self.output_dim[1]))\n",
        "        lcp_imag = tf.reshape(lcp_imag, (-1, self.output_dim[0], self.output_dim[1]))\n",
        "\n",
        "        rcp = tf.stack([rcp_real, rcp_imag], axis=1)\n",
        "        lcp = tf.stack([lcp_real, lcp_imag], axis=1)\n",
        "\n",
        "        cmpx = tf.stack([rcp, lcp], axis=1)\n",
        "\n",
        "        if self.normalization == 'max':\n",
        "            absmax = tf.reduce_max(tf.abs(cmpx))\n",
        "            cmpx = cmpx / absmax\n",
        "\n",
        "        return cmpx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8nG7x1gC5FrO",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class CxD2NNIntensity(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim, normalization='min_max', **kwargs):\n",
        "        super(CxD2NNIntensity, self).__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.normalization = normalization\n",
        "\n",
        "    def call(self, x, **kwargs):\n",
        "        x_rcp_real = Lambda(lambda x: x[:,0, 0, :, :])(x)\n",
        "        x_rcp_imag = Lambda(lambda x: x[:,0, 1, :, :])(x)\n",
        "        x_lcp_real = Lambda(lambda x: x[:,1, 0, :, :])(x)\n",
        "        x_lcp_imag = Lambda(lambda x: x[:,1, 1, :, :])(x)\n",
        "        i_rcp = tf.sqrt(x_rcp_real ** 2 + x_rcp_imag ** 2)\n",
        "        i_lcp = tf.sqrt(x_lcp_real ** 2 + x_lcp_imag ** 2)\n",
        "        intensity = (i_rcp + i_lcp) / 2\n",
        "        if self.normalization == 'min_max':\n",
        "            max = tf.reduce_max(intensity)\n",
        "            min = tf.reduce_min(intensity)\n",
        "            intensity = (intensity - min) / (max - min)\n",
        "        if self.normalization == 'max':\n",
        "            max = tf.reduce_max(intensity)\n",
        "            intensity = intensity / max\n",
        "\n",
        "        return intensity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "class CxD2NNEllipticity(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super(CxD2NNEllipticity, self).__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, x, **kwargs):\n",
        "        x_rcp_real = Lambda(lambda x: x[:,0, 0, :, :])(x)\n",
        "        x_rcp_imag = Lambda(lambda x: x[:,0, 1, :, :])(x)\n",
        "        x_lcp_real = Lambda(lambda x: x[:,1, 0, :, :])(x)\n",
        "        x_lcp_imag = Lambda(lambda x: x[:,1, 1, :, :])(x)\n",
        "        i_rcp = tf.sqrt(x_rcp_real ** 2 + x_rcp_imag ** 2)\n",
        "        i_lcp = tf.sqrt(x_lcp_real ** 2 + x_lcp_imag ** 2)\n",
        "        ellipticity = (i_rcp - i_lcp)/(i_rcp + i_lcp)\n",
        "\n",
        "        return ellipticity"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dzVk5Uaemr_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "source": [
        "class CxD2NNMNISTDetector(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_dim, activation=None, **kwargs):\n",
        "        super(CxD2NNMNISTDetector, self).__init__(**kwargs)\n",
        "        self.output_dim = output_dim\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_dim = input_shape\n",
        "        self.width = min(int(tf.floor(self.input_dim[2] / 9.0)), int(tf.floor(self.input_dim[1] / 7.0)))\n",
        "        self.height = min(int(tf.floor(self.input_dim[2] / 9.0)), int(tf.floor(self.input_dim[1] / 7.0)))\n",
        "        super(CxD2NNMNISTDetector, self).build(input_shape)\n",
        "\n",
        "    def plot_area(self, input_shape, same_color=False):\n",
        "        width = min(int(np.floor(input_shape[1] / 9.0)), int(np.floor(input_shape[0] / 7.0)))\n",
        "        height = min(int(np.floor(input_shape[1] / 9.0)), int(np.floor(input_shape[0] / 7.0)))\n",
        "        x = np.zeros(input_shape)\n",
        "        if same_color:\n",
        "            x[2 * height:3 * height, width:2 * width] = 1\n",
        "            x[2 * height:3 * height, 4 * width:5 * width] = 1\n",
        "            x[2 * height:3 * height, 7 * width:8 * width] = 1\n",
        "            x[4 * height:5 * height, 1 * width:2 * width] = 1\n",
        "            x[4 * height:5 * height, 3 * width:4 * width] = 1\n",
        "            x[4 * height:5 * height, 5 * width:6 * width] = 1\n",
        "            x[4 * height:5 * height, 7 * width:8 * width] = 1\n",
        "            x[6 * height:7 * height, width:2 * width] = 1\n",
        "            x[6 * height:7 * height, 4 * width:5 * width] = 1\n",
        "            x[6 * height:7 * height, 7 * width:8 * width] = 1\n",
        "        else:\n",
        "            x[2 * height:3 * height, width:2 * width] = 1\n",
        "            x[2 * height:3 * height, 4 * width:5 * width] = 2\n",
        "            x[2 * height:3 * height, 7 * width:8 * width] = 3\n",
        "            x[4 * height:5 * height, 1 * width:2 * width] = 4\n",
        "            x[4 * height:5 * height, 3 * width:4 * width] = 5\n",
        "            x[4 * height:5 * height, 5 * width:6 * width] = 6\n",
        "            x[4 * height:5 * height, 7 * width:8 * width] = 7\n",
        "            x[6 * height:7 * height, width:2 * width] = 8\n",
        "            x[6 * height:7 * height, 4 * width:5 * width] = 9\n",
        "            x[6 * height:7 * height, 7 * width:8 * width] = 10\n",
        "        plt.imshow(x)\n",
        "\n",
        "    def call(self, x, **kwargs):\n",
        "        y0 = x[:, 2 * self.height:3 * self.height, self.width:2 * self.width]\n",
        "        y1 = x[:, 2 * self.height:3 * self.height, 4 * self.width:5 * self.width]\n",
        "        y2 = x[:, 2 * self.height:3 * self.height, 7 * self.width:8 * self.width]\n",
        "        y3 = x[:, 4 * self.height:5 * self.height, self.width:2 * self.width]\n",
        "        y4 = x[:, 4 * self.height:5 * self.height, 3 * self.width:4 * self.width]\n",
        "        y5 = x[:, 4 * self.height:5 * self.height, 5 * self.width:6 * self.width]\n",
        "        y6 = x[:, 4 * self.height:5 * self.height, 7 * self.width:8 * self.width]\n",
        "        y7 = x[:, 6 * self.height:7 * self.height, self.width:2 * self.width]\n",
        "        y8 = x[:, 6 * self.height:7 * self.height, 4 * self.width:5 * self.width]\n",
        "        y9 = x[:, 6 * self.height:7 * self.height, 7 * self.width:8 * self.width]\n",
        "        y0 = tf.reduce_sum(y0, axis=[1])\n",
        "        y0 = tf.reduce_sum(y0, axis=[1], keepdims=True)\n",
        "        y1 = tf.reduce_sum(y1, axis=[1])\n",
        "        y1 = tf.reduce_sum(y1, axis=[1], keepdims=True)\n",
        "        y2 = tf.reduce_sum(y2, axis=[1])\n",
        "        y2 = tf.reduce_sum(y2, axis=[1], keepdims=True)\n",
        "        y3 = tf.reduce_sum(y3, axis=[1])\n",
        "        y3 = tf.reduce_sum(y3, axis=[1], keepdims=True)\n",
        "        y4 = tf.reduce_sum(y4, axis=[1])\n",
        "        y4 = tf.reduce_sum(y4, axis=[1], keepdims=True)\n",
        "        y5 = tf.reduce_sum(y5, axis=[1])\n",
        "        y5 = tf.reduce_sum(y5, axis=[1], keepdims=True)\n",
        "        y6 = tf.reduce_sum(y6, axis=[1])\n",
        "        y6 = tf.reduce_sum(y6, axis=[1], keepdims=True)\n",
        "        y7 = tf.reduce_sum(y7, axis=[1])\n",
        "        y7 = tf.reduce_sum(y7, axis=[1], keepdims=True)\n",
        "        y8 = tf.reduce_sum(y8, axis=[1])\n",
        "        y8 = tf.reduce_sum(y8, axis=[1], keepdims=True)\n",
        "        y9 = tf.reduce_sum(y9, axis=[1])\n",
        "        y9 = tf.reduce_sum(y9, axis=[1], keepdims=True)\n",
        "        y = tf.keras.layers.concatenate([y0, y1, y2, y3, y4, y5, y6, y7, y8, y9])\n",
        "\n",
        "        if self.activation == 'softmax':\n",
        "            y = tf.nn.softmax(y)\n",
        "        return y"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "t4WESu2lmr_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Dpt-HgVUOdqH"
      },
      "outputs": [],
      "source": [
        "def create_true_mnistimage(label, shape):\n",
        "    width = min(int(np.floor(shape[1] / 9.0)), int(np.floor(shape[0] / 7.0)))\n",
        "    height = min(int(np.floor(shape[1] / 9.0)), int(np.floor(shape[0] / 7.0)))\n",
        "    x = np.zeros(shape)\n",
        "\n",
        "    if label == 0:\n",
        "        x[2 * height:3 * height, width:2 * width] = 1.0\n",
        "    elif label == 1:\n",
        "        x[2 * height:3 * height, 4 * width:5 * width] = 1.0\n",
        "    elif label == 2:\n",
        "        x[2 * height:3 * height, 7 * width:8 * width] = 1.0\n",
        "    elif label == 3:\n",
        "        x[4 * height:5 * height, 1 * width:2 * width] = 1.0\n",
        "    elif label == 4:\n",
        "        x[4 * height:5 * height, 3 * width:4 * width] = 1.0\n",
        "    elif label == 5:\n",
        "        x[4 * height:5 * height, 5 * width:6 * width] = 1.0\n",
        "    elif label == 6:\n",
        "        x[4 * height:5 * height, 7 * width:8 * width] = 1.0\n",
        "    elif label == 7:\n",
        "        x[6 * height:7 * height, width:2 * width] = 1.0\n",
        "    elif label == 8:\n",
        "        x[6 * height:7 * height, 4 * width:5 * width] = 1.0\n",
        "    elif label == 9:\n",
        "        x[6 * height:7 * height, 7 * width:8 * width] = 1.0\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "RLvSiiMoOgg5",
        "outputId": "de3e31ed-5c89-4423-c025-94b9a62ce841"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "<matplotlib.image.AxesImage at 0x7fb45bd33240>"
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(create_true_mnistimage(9, (50, 50)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nIoyHqA5FrP",
        "outputId": "ee67a9fa-70c2-4ab6-a026-72c129ae576d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "image_shape = (28, 28)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = np.array(list(map(lambda image: cv2.resize(image, dsize=image_shape), x_train)))\n",
        "x_test = np.array(list(map(lambda image: cv2.resize(image, dsize=image_shape), x_test)))\n",
        "y_train_image = np.array(list(map(lambda y_label: create_true_mnistimage(y_label, image_shape), y_train)))\n",
        "y_test_image = np.array(list(map(lambda y_label: create_true_mnistimage(y_label, image_shape), y_test)))\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "RHqUdqQpOk1l",
        "outputId": "129e2118-05ed-4fa1-c533-b1e919451e11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAK80lEQVR4nO3dX6jf9X3H8edrNkaaVjDtFqKVtSsykMLScYiDyuhwrdab2JvSXBQHwulFhQqFTbqLeRm2dWUXo5CuodnoLINW6oXMZqEghRGMkmnUbXGS0sSYrMtF7GAx2vcuzjflVM8/f/+z9/MBh9/v9/39zu/75kue+f05v3M+qSok/f/3a/MeQNJsGLvUhLFLTRi71ISxS028Z5Y7uz7b6wZ2zHKXUiv/y//wRl3OWteNFXuSe4C/Bq4D/raqDmx0+xvYwR25a5xdStrAsTq67nUjP41Pch3wN8BngNuB/UluH/X+JE3XOK/Z9wIvV9UrVfUG8F1g32TGkjRp48R+C/DTVZfPDNt+RZLlJMeTHL/C5TF2J2kcU383vqoOVtVSVS1tY/u0dydpHePEfha4ddXlDw3bJC2gcWJ/GrgtyUeSXA98Hnh8MmNJmrSRf/RWVW8meRB4kpUfvR2qqhcmNpmkiRrr5+xV9QTwxIRmkTRFflxWasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJsZasjnJaeB14C3gzapamsRQkiZvrNgHf1BVP5vA/UiaIp/GS02MG3sBP0zyTJLltW6QZDnJ8STHr3B5zN1JGtW4T+PvrKqzSX4DOJLk36rqqdU3qKqDwEGAG7OzxtyfpBGN9cheVWeH0wvAY8DeSQwlafJGjj3JjiTvv3oe+DRwclKDSZqscZ7G7wIeS3L1fv6hqv5pIlON4MlXT0z1/u++ec9U739aPC5r63hcRo69ql4BfmeCs0iaIn/0JjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41karZLdJyY3bWHblrZvuTujlWR7lUF7PWdT6yS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9TEprEnOZTkQpKTq7btTHIkyanh9KbpjilpXFt5ZP82cM/btj0MHK2q24Cjw2VJC2zT2KvqKeDi2zbvAw4P5w8D9014LkkT9p4Rv29XVZ0bzr8G7FrvhkmWgWWAG3jviLuTNK6x36Crld+kWfe3aarqYFUtVdXSNraPuztJIxo19vNJdgMMpxcmN5KkaRg19seB+4fz9wM/mMw4kqZlKz96exT4F+C3k5xJ8gBwAPhUklPAHw6XJS2wTd+gq6r961zlX6GQriF+gk5qwtilJoxdasLYpSaMXWpi1I/LLpwnXz0x1fu/++Y9U7vvac4+zbnh2p39Wv73Miof2aUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSZSVTPb2Y3ZWXfExV+laTlWR7lUF7PWdVtZn/1QkgtJTq7a9kiSs0lODF/3TnJgSZO3lafx3wbuWWP716tqz/D1xGTHkjRpm8ZeVU8BF2cwi6QpGucNugeTPDc8zb9pvRslWU5yPMnxK1weY3eSxjFq7N8APgrsAc4BX1vvhlV1sKqWqmppG9tH3J2kcY0Ue1Wdr6q3quoXwDeBvZMdS9KkjRR7kt2rLn4WOLnebSUthk3XZ0/yKPBJ4INJzgB/BnwyyR6ggNPAF6c4o6QJ2DT2qtq/xuZvTWEWSVPkx2WlJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJjb9rbdrxZOvnpjq/d99856p3v+0eFzW1vG4+MguNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITm8ae5NYkP0ryYpIXknx52L4zyZEkp4bTm6Y/rqRRbeWR/U3gK1V1O/B7wJeS3A48DBytqtuAo8NlSQtq09ir6lxVPTucfx14CbgF2AccHm52GLhvWkNKGt+7+ht0ST4MfBw4BuyqqnPDVa8Bu9b5nmVgGeAG3jvqnJLGtOU36JK8D/ge8FBVXVp9XVUVUGt9X1UdrKqlqlraxvaxhpU0ui3FnmQbK6F/p6q+P2w+n2T3cP1u4MJ0RpQ0CVl5UN7gBklYeU1+saoeWrX9L4D/rqoDSR4GdlbVH290XzdmZ92RuyYwtqS1HKujXKqLWeu6rbxm/wTwBeD5JFf/2PZXgQPAPyZ5APgJ8LlJDCtpOjaNvap+DKz5PwXgw7R0jfATdFITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhObxp7k1iQ/SvJikheSfHnY/kiSs0lODF/3Tn9cSaPayvrsbwJfqapnk7wfeCbJkeG6r1fVX05vPEmTspX12c8B54bzryd5Cbhl2oNJmqx39Zo9yYeBjwPHhk0PJnkuyaEkN63zPctJjic5foXLYw0raXRbjj3J+4DvAQ9V1SXgG8BHgT2sPPJ/ba3vq6qDVbVUVUvb2D6BkSWNYkuxJ9nGSujfqarvA1TV+ap6q6p+AXwT2Du9MSWNayvvxgf4FvBSVf3Vqu27V93ss8DJyY8naVK28m78J4AvAM8nOTFs+yqwP8keoIDTwBenMqGkidjKu/E/BrLGVU9MfhxJ0+In6KQmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qIlU1u50l/wX8ZNWmDwI/m9kA786izraoc4GzjWqSs/1mVf36WlfMNPZ37Dw5XlVLcxtgA4s626LOBc42qlnN5tN4qQljl5qYd+wH57z/jSzqbIs6FzjbqGYy21xfs0uanXk/skuaEWOXmphL7EnuSfLvSV5O8vA8ZlhPktNJnh+WoT4+51kOJbmQ5OSqbTuTHElyajhdc429Oc22EMt4b7DM+FyP3byXP5/5a/Yk1wH/AXwKOAM8DeyvqhdnOsg6kpwGlqpq7h/ASPL7wM+Bv6uqjw3b/hy4WFUHhv8ob6qqP1mQ2R4Bfj7vZbyH1Yp2r15mHLgP+CPmeOw2mOtzzOC4zeORfS/wclW9UlVvAN8F9s1hjoVXVU8BF9+2eR9weDh/mJV/LDO3zmwLoarOVdWzw/nXgavLjM/12G0w10zMI/ZbgJ+uunyGxVrvvYAfJnkmyfK8h1nDrqo6N5x/Ddg1z2HWsOky3rP0tmXGF+bYjbL8+bh8g+6d7qyq3wU+A3xpeLq6kGrlNdgi/ex0S8t4z8oay4z/0jyP3ajLn49rHrGfBW5ddflDw7aFUFVnh9MLwGMs3lLU56+uoDucXpjzPL+0SMt4r7XMOAtw7Oa5/Pk8Yn8auC3JR5JcD3weeHwOc7xDkh3DGyck2QF8msVbivpx4P7h/P3AD+Y4y69YlGW811tmnDkfu7kvf15VM/8C7mXlHfn/BP50HjOsM9dvAf86fL0w79mAR1l5WneFlfc2HgA+ABwFTgH/DOxcoNn+HngeeI6VsHbPabY7WXmK/hxwYvi6d97HboO5ZnLc/Lis1IRv0ElNGLvUhLFLTRi71ISxS00Yu9SEsUtN/B91uX8BgAVAUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "detector = CxD2NNMNISTDetector(10)\n",
        "detector.plot_area((28, 28), same_color=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KDVIT-b55FrP",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def loss(y_hat, y):\n",
        "    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_hat, logits=y)\n",
        "\n",
        "\n",
        "def loss_MSE(y_hat, y):\n",
        "    return tf.reduce_sum((y_hat - y) ** 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s0rXpHct5FrP",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "l = 633e-9\n",
        "k = 2 * np.pi / l\n",
        "d = 1e-6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiKvMSZo5FrQ",
        "outputId": "8a2d0756-5f6e-4aab-bc9f-564d253ea7ae",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "input_to_cx_1 (InputToCx)    (None, 2, 2, 28, 28)      0         \n",
            "_________________________________________________________________\n",
            "cx_mo_1 (CxMO)               (None, 2, 2, 28, 28)      784       \n",
            "_________________________________________________________________\n",
            "free_space_propagation_1 (Fr (None, 2, 2, 28, 28)      1229312   \n",
            "_________________________________________________________________\n",
            "cx_d2nn_intensity (CxD2NNInt (None, 28, 28)            0         \n",
            "_________________________________________________________________\n",
            "cx_d2nnmnist_detector_1 (CxD (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,230,096\n",
            "Trainable params: 784\n",
            "Non-trainable params: 1,229,312\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "19264/60000 [========>.....................] - ETA: 30s - loss: 2.6878 - accuracy: 0.1336"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4a3547ead140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                    \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                    \u001b[0;31m#callbacks=[early_stopping]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                    )\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/opt/anaconda3/envs/MOD2NN/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(image_shape)\n",
        "x = InputToCx(image_shape)(inputs)\n",
        "x = CxMO(image_shape)(x)\n",
        "x = FreeSpacePropagation(image_shape, k, 1.0e-4, normalization='max', input_pitch=2.0e-6, output_pitch=2.0e-6)(x)\n",
        "x = CxD2NNIntensity(image_shape, normalization='max')(x)\n",
        "x = CxD2NNMNISTDetector(10, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, x)\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",  # category: sparse_categorical_crossentropy\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "epochs = 10\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    min_delta=0.05,\n",
        "    patience=2,\n",
        ")\n",
        "\n",
        "result = model.fit(x_train,\n",
        "                   y_train,\n",
        "                   batch_size=64,\n",
        "                   epochs=epochs\n",
        "                   #callbacks=[early_stopping]\n",
        "                   )\n",
        "model.save(\"28x28_6(MO_frspc100um)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oypp3Gc8obCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psxg1H6WiyKn"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 6))\n",
        "ax1 = fig.add_subplot(111)\n",
        "ax2 = ax1.twinx()\n",
        "ax1.plot(range(1, epochs + 1), result.history['loss'], color='black', label='Loss')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax2.plot(range(1, epochs + 1), result.history['accuracy'], color='red', label='Accuracy')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "# label1と2には、凡例用に各labelのリスト情報が入る\n",
        "handler1, label1 = ax1.get_legend_handles_labels()\n",
        "handler2, label2 = ax2.get_legend_handles_labels()\n",
        "# 凡例をまとめて出力する\n",
        "ax1.legend(handler1 + handler2, label1 + label2, loc=2, borderaxespad=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPPH451APLgm"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGBtRuwC5FrQ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "layer_name = model.layers[-2].name\n",
        "hidden_layer_model = tf.keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "hidden_layer_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM6fAIqU5FrQ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "num = 5\n",
        "images = x_train[0:num, :, :]\n",
        "\n",
        "preds = model.predict(images)\n",
        "pred_images = hidden_layer_model.predict(images)\n",
        "fig, axes = plt.subplots(num, 3, figsize=(7, 10))\n",
        "for i in range(num):\n",
        "    axes[i, 0].imshow(images[i, :, :])\n",
        "    axes[i, 1].imshow(pred_images[i, :, :])\n",
        "    axes[i, 2].bar(np.arange(0, 10, 1), preds[i, :], align='center')\n",
        "    axes[i, 2].set_xticks(np.arange(0, 10, 1))\n",
        "    axes[i, 2].set_ylabel('Accuracy')\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsYnMu1DPVkh"
      },
      "outputs": [],
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[1:]]\n",
        "layer_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlTNml_9PYWA"
      },
      "outputs": [],
      "source": [
        "activation_model = keras.Model(inputs=model.input, outputs=layer_outputs)\n",
        "activation_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v-O4IwHPaoH"
      },
      "outputs": [],
      "source": [
        "num = 5\n",
        "images = x_train[0:num, :, :]\n",
        "activations = activation_model.predict(images)\n",
        "len(activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq_5Zpj5Pgeh"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(num, len(activations) - 2, figsize=(2 * len(activations) - 1, 2 * num))\n",
        "for i in range(len(activations) - 2):\n",
        "    layer_activation = activations[i]\n",
        "    for j in range(num):\n",
        "        intensity = tf.sqrt(layer_activation[j, 0, :, :] ** 2 + layer_activation[j, 1, :, :] ** 2)\n",
        "        axes[j, i].imshow(intensity)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = 10\n",
        "test_num = 10\n",
        "total = train_num + test_num\n",
        "train_data = {}\n",
        "test_data = {}\n",
        "for i in range(10):\n",
        "  train_data[str(i)] = x_train[np.where(y_train[:1000] == i)][0:train_num]\n",
        "  test_data[str(i)] = x_test[np.where(y_test[:1000] == i)][0:test_num]"
      ],
      "metadata": {
        "id": "r-yJfhzooeso"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VxaIpZG3mr_P",
        "outputId": "15c8238e-aab9-47a3-f6bb-731f830e71c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " input_to_cx (InputToCx)     (None, 2, 2, 28, 28)      0         \n",
            "                                                                 \n",
            " free_space_propagation (Fre  (None, 2, 2, 28, 28)     1229312   \n",
            " eSpacePropagation)                                              \n",
            "                                                                 \n",
            " cx_d2nn_intensity (CxD2NNIn  (None, 28, 28)           0         \n",
            " tensity)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,229,312\n",
            "Trainable params: 0\n",
            "Non-trainable params: 1,229,312\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input((28, 28))\n",
        "x = InputToCx((28, 28))(inputs)\n",
        "x = FreeSpacePropagation((28, 28), k, 1.0e-4)(x)\n",
        "x = CxD2NNIntensity((28, 28))(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, x)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_data[\"1\"][2, :, :])"
      ],
      "metadata": {
        "id": "y3zu2JA9oxeq",
        "outputId": "6116aa8a-0c1d-4ccf-a62c-463e5f24a9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fefda58a5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7oBRICyimr_Q",
        "outputId": "f160e52c-99f0-4284-9b99-fcd0ab81b426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "pred = model.predict((train_data[\"5\"]))\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Zyn5xkcQmr_Q",
        "outputId": "07f16b8c-b26f-4132-b2b5-223fa7caf62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fefdaf53950>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(pred[4,:,:])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}